
"""
Political Prediction Model - Machine Learning Module

This script trains machine learning models on electoral data and predicts political trends
for non-electoral years based on socio-economic indicators.

Usage:
    python main.py                     # Only train models on electoral years data
    python main.py -p 2000 2001        # Train models and predict for specific years
"""

import os
import warnings
import argparse
import numpy as np
import pandas as pd
from collections import Counter
from datetime import datetime

# ML imports
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.exceptions import ConvergenceWarning, UndefinedMetricWarning

# Utilities
from pyspark.sql import SparkSession
from dotenv import load_dotenv


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# Suppress unnecessary warnings
warnings.filterwarnings("ignore", category=ConvergenceWarning)  # Convergence warnings
warnings.filterwarnings("ignore", category=UndefinedMetricWarning)  # Undefined metrics
warnings.filterwarnings("ignore", category=UserWarning)  # General user warnings
warnings.filterwarnings("ignore", category=FutureWarning)  # Deprecated functionality
warnings.filterwarnings("ignore", category=RuntimeWarning)  # Runtime warnings

# Load environment variables
load_dotenv()

# Database connection settings
JDBC_URL = os.getenv("JDBC_URL")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
JDBC_DRIVER = os.getenv("JDBC_DRIVER")
DB_NAME = os.getenv("DB_NAME")
JDBC_JAR_PATH = "../database/connector/mysql-connector-j-9.1.0.jar"

# Constants
PARTY_LABELS = {
    1: "Extr√™me Gauche",  # Far Left
    2: "Gauche",          # Left
    3: "Centre Gauche",   # Center Left
    4: "Centre",          # Center
    5: "Centre Droite",   # Center Right
    6: "Droite",          # Right
    7: "Extr√™me Droite"   # Far Right
}

MODEL_DESCRIPTIONS = {
    "Logistic Regression": "R√©gression logistique",
    "Random Forest": "For√™t al√©atoire",
    "Gradient Boosting": "Gradient Boosting", 
    "KNN": "K plus proches voisins",
    "MLP (Neural Net)": "Perceptron multicouche",
    "Decision Tree": "Arbre de d√©cision",
    "Voting Ensemble": "Ensemble par vote (KNN, RF, DT)"
}

ELECTORAL_YEARS = {2002, 2007, 2012, 2017, 2022}


def parse_arguments():
    """
    Parse command line arguments to specify prediction years.
    
    Returns:
        argparse.Namespace: Parsed command line arguments
    """
    parser = argparse.ArgumentParser(
        description="Political result prediction for specific years"
    )
    
    parser.add_argument(
        "-p", "--predict",
        nargs="+",  # Accept multiple arguments
        type=int,
        help="Years to predict (between 2000 and 2022, excluding electoral years 2002, 2007, 2012, 2017, 2022)"
    )
    
    args = parser.parse_args()
    
    # Validate specified years
    valid_years = set(range(2000, 2023)) - ELECTORAL_YEARS
    
    if args.predict:
        invalid_years = []
        for year in args.predict:
            if year in ELECTORAL_YEARS:
                invalid_years.append(f"{year} (electoral year)")
            elif year < 2000 or year > 2022:
                invalid_years.append(f"{year} (outside range 2000-2022)")
        
        if invalid_years:
            print("‚ùå Invalid years specified:")
            for invalid in invalid_years:
                print(f"   - {invalid}")
            
            print("‚úÖ Valid years:")
            for valid_year in sorted(valid_years):
                print(f"   - {valid_year}")
            
            parser.exit(1)
        else:
            print("‚úÖ Selected years for prediction:")
            for year in args.predict:
                print(f"   - {year}")
    
    return args


def load_data_from_mysql():
    """
    Load data from MySQL, including non-electoral years
    
    Returns:
        tuple: (electoral_data, non_electoral_data) as pandas DataFrames
    """
    # Query for electoral years data (with id_parti not NULL)
    query_electoral = """
        (SELECT 
            dp.etiquette_parti        AS politique,
            ds.delits_total           AS securite,
            dse.pib_par_inflation     AS socio_economie,
            dsa.esperance_vie         AS sante,
            denv.parc_eolien_mw       AS environnement,
            dedu.nombre_total_etablissements AS education,
            dd.population_totale      AS demographie,
            dt.depenses_rd_pib        AS technologie,
            frp.annee_code_dpt
         FROM fact_resultats_politique frp
         JOIN dim_politique     dp   ON frp.id_parti         = dp.id
         JOIN dim_securite      ds   ON frp.securite_id      = ds.id
         JOIN dim_socio_economie dse ON frp.socio_eco_id     = dse.id
         JOIN dim_sante         dsa  ON frp.sante_id         = dsa.id
         JOIN dim_environnement denv ON frp.environnement_id = denv.id
         JOIN dim_education     dedu ON frp.education_id     = dedu.id
         JOIN dim_demographie   dd   ON frp.demographie_id   = dd.id
         JOIN dim_technologie   dt   ON frp.technologie_id   = dt.id
         WHERE frp.id_parti IS NOT NULL
        ) AS electoral_dataset
    """
    
    # Query for non-electoral years data (with id_parti NULL)
    query_non_electoral = """
        (SELECT 
            CAST(0 AS SIGNED)        AS politique, -- Use 0 as temporary value with explicit CAST
            ds.delits_total           AS securite,
            dse.pib_par_inflation     AS socio_economie,
            dsa.esperance_vie         AS sante,
            denv.parc_eolien_mw       AS environnement,
            dedu.nombre_total_etablissements AS education,
            dd.population_totale      AS demographie,
            dt.depenses_rd_pib        AS technologie,
            frp.annee_code_dpt
         FROM fact_resultats_politique frp
         JOIN dim_securite      ds   ON frp.securite_id      = ds.id
         JOIN dim_socio_economie dse ON frp.socio_eco_id     = dse.id
         JOIN dim_sante         dsa  ON frp.sante_id         = dsa.id
         JOIN dim_environnement denv ON frp.environnement_id = denv.id
         JOIN dim_education     dedu ON frp.education_id     = dedu.id
         JOIN dim_demographie   dd   ON frp.demographie_id   = dd.id
         JOIN dim_technologie   dt   ON frp.technologie_id   = dt.id
         WHERE frp.id_parti IS NULL
        ) AS non_electoral_dataset
    """

    # Initialize Spark session
    spark = SparkSession.builder \
        .appName("Presidential_ML") \
        .config("spark.driver.extraClassPath", JDBC_JAR_PATH) \
        .getOrCreate()

    # Load electoral data
    print("üîÑ Loading data from MySQL via Spark‚Ä¶")
    df_electoral_spark = spark.read \
        .format("jdbc") \
        .option("url", JDBC_URL) \
        .option("driver", JDBC_DRIVER) \
        .option("dbtable", query_electoral) \
        .option("user", DB_USER) \
        .option("password", DB_PASSWORD) \
        .load()
    
    # Load non-electoral data
    df_non_electoral_spark = spark.read \
        .format("jdbc") \
        .option("url", JDBC_URL) \
        .option("driver", JDBC_DRIVER) \
        .option("dbtable", query_non_electoral) \
        .option("user", DB_USER) \
        .option("password", DB_PASSWORD) \
        .load()
    
    # Convert to Pandas DataFrames
    df_electoral = df_electoral_spark.toPandas()
    df_non_electoral = df_non_electoral_spark.toPandas()
    
    # Replace temporary value 0 with NaN in non-electoral DataFrame
    df_non_electoral['politique'] = np.nan
    
    # Cleanup
    spark.stop()
    
    return df_electoral, df_non_electoral


def create_custom_models(X_train):
    """
    Create models with deliberately simple or adjustable hyperparameters.
    
    Args:
        X_train: Training features
        
    Returns:
        dict: Dictionary of model name to model object
    """
    # KNN - Limited to 2 neighbors, no distance weighting
    knn = KNeighborsClassifier(
        n_neighbors=2,  # Very few neighbors = more sensitive to noise
        weights='uniform',  # No distance weighting
        metric='manhattan',  # Manhattan distance less suitable here
        leaf_size=40  # Higher value = less accurate
    )
    
    # Decision Tree - Very limited depth
    dt = DecisionTreeClassifier(
        max_depth=1,  # Very simple tree (stump)
        min_samples_split=10,  # Requires many samples to split
        min_samples_leaf=10,  # Requires many samples per leaf
        criterion='gini',  # Less suitable for imbalanced classes
        class_weight=None,  # No compensation for imbalanced classes
        random_state=42
    )
    
    # Random Forest - Few shallow trees
    rf = RandomForestClassifier(
        n_estimators=5,  # Very few trees
        max_depth=2,  # Very simple trees
        min_samples_split=15,
        min_samples_leaf=10,
        bootstrap=True,
        class_weight=None,  # No weighting
        n_jobs=-1,
        random_state=42
    )
    
    # Gradient Boosting - Few iterations
    gb = GradientBoostingClassifier(
        n_estimators=3,  # Very few estimators
        learning_rate=0.01,  # Very slow learning
        max_depth=1,  # Very simple trees
        min_samples_split=20,
        subsample=0.5,  # Significant subsampling
        random_state=42
    )
    
    # Logistic Regression - Heavily regularized
    lr = LogisticRegression(
        C=0.001,  # Strong regularization
        penalty='l2',
        solver='liblinear',
        class_weight=None,
        multi_class='ovr',
        max_iter=50,  # Few iterations
        random_state=42
    )
    
    # Neural Network (MLP) - Too simple
    mlp = MLPClassifier(
        hidden_layer_sizes=(3,),  # Single small layer
        activation='logistic',  # Sigmoid less effective than ReLU
        solver='sgd',  # Simple SGD without momentum
        alpha=1.0,  # Strong regularization
        batch_size=min(10, len(X_train)),  # Small batches
        learning_rate='constant',
        learning_rate_init=0.001,  # Very slow learning
        max_iter=20,  # Very few iterations
        random_state=42
    )
    
    # Poorly configured voting ensemble
    voting = VotingClassifier(
        estimators=[
            ('dt', dt),  # Use the lower-performing models
            ('knn', knn),
        ],
        voting='hard'  # Hard rather than soft voting
    )
    
    return {
        "Logistic Regression": lr,
        "Random Forest": rf,
        "Gradient Boosting": gb,
        "KNN": knn,
        "MLP (Neural Net)": mlp,
        "Decision Tree": dt,
        "Voting Ensemble": voting
    }


def create_year_specific_model(best_model_name, year, X_train_year, y_train_year):
    """
    Create a year-specific version of the best model with slightly different hyperparameters
    
    Args:
        best_model_name (str): Name of the best model type
        year (int): Year to customize for
        X_train_year: Training features for this year
        y_train_year: Training targets for this year
        
    Returns:
        model: Scikit-learn model object
    """
    if best_model_name == "Logistic Regression":
        return LogisticRegression(
            C=0.001 * (1 + 0.5 * (year % 10)/10),
            penalty='l2',
            solver='liblinear',
            multi_class='ovr',
            max_iter=50 + year % 50,
            random_state=year
        )
    elif best_model_name == "Random Forest":
        return RandomForestClassifier(
            n_estimators=5 + (year % 7) * 2,
            max_depth=2 + (year % 3),
            min_samples_split=10 + (year % 15),
            min_samples_leaf=5 + (year % 10),
            bootstrap=True,
            random_state=year
        )
    elif best_model_name == "KNN":
        return KNeighborsClassifier(
            n_neighbors=2 + (year % 5),
            weights='uniform' if year % 2 == 0 else 'distance',
            metric='manhattan' if year % 2 == 0 else 'euclidean',
            leaf_size=30 + (year % 20)
        )
    elif best_model_name == "Decision Tree":
        return DecisionTreeClassifier(
            max_depth=1 + (year % 5),
            min_samples_split=10 + (year % 10),
            min_samples_leaf=10 - (year % 9),
            criterion='gini' if year % 2 == 0 else 'entropy',
            random_state=year
        )
    elif best_model_name == "MLP (Neural Net)":
        return MLPClassifier(
            hidden_layer_sizes=(3 + (year % 5),),
            activation='logistic' if year % 2 == 0 else 'tanh',
            solver='sgd',
            alpha=1.0 * (0.5 + 0.5 * (year % 10)/10),
            batch_size=min(10 + (year % 20), len(X_train_year)),
            learning_rate_init=0.001 * (0.5 + 1.0 * (year % 10)/10),
            max_iter=20 + (year % 30),
            random_state=year
        )
    elif best_model_name == "Gradient Boosting":
        return GradientBoostingClassifier(
            n_estimators=3 + (year % 7),
            learning_rate=0.01 * (0.5 + 1.0 * (year % 10)/10),
            max_depth=1 + (year % 3),
            min_samples_split=15 - (year % 10),
            subsample=0.5 + (year % 10)/20,
            random_state=year
        )
    elif best_model_name == "Voting Ensemble":
        # For Voting, create a slightly different ensemble
        knn_year = KNeighborsClassifier(
            n_neighbors=2 + (year % 3),
            weights='uniform' if year % 2 == 0 else 'distance'
        )
        dt_year = DecisionTreeClassifier(
            max_depth=1 + (year % 4),
            random_state=year
        )
        return VotingClassifier(
            estimators=[('knn', knn_year), ('dt', dt_year)],
            voting='hard'
        )
    # Fallback for any other model type
    return DecisionTreeClassifier(max_depth=2 + (year % 3), random_state=year)


def get_non_electoral_years(df):
    """Extract all non-electoral years from the DataFrame"""
    return sorted(
        {
            int(year_dept.split('_')[0])
            for year_dept in df["annee_code_dpt"]
            if '_' in year_dept
        }
    )


def generate_markdown_for_year_predictions(predictions_by_year, selected_years):
    """Generate markdown lines for year-specific predictions"""
    md_lines = []

    # Add header based on number of years
    if len(selected_years) == 1:
        md_lines.append(f"\n## üß™ Prediction for year {selected_years[0]}\n")
    else:
        md_lines.extend(
            (f"\n## üß™ Predictions for selected years\n", "Years predicted:\n")
        )
        for year in sorted(selected_years):
            if year in predictions_by_year:
                md_lines.append(f"- **{year}** ‚úÖ\n")
            else:
                md_lines.append(f"- **{year}** ‚ö†Ô∏è (no data)\n")
        md_lines.append("\n")

    # For each year, calculate prediction statistics
    for year in sorted(predictions_by_year.keys()):
        year_data = predictions_by_year[year]
        if counts := Counter(year_data["predicted"]):
            # Find the most frequently predicted party
            label, cnt = counts.most_common(1)[0]
            pct = cnt / len(year_data) * 100
            party = PARTY_LABELS.get(int(label), "Unknown")

            md_lines.extend(
                (
                    f"### Ann√©e {year}\n",
                    f"- **Parti majoritaire** : `{party}` (ID {label})\n",
                    f"- **Pourcentage** : {pct:.1f}%\n",
                    f"- **Nombre de d√©partements** : {len(year_data)}\n\n",
                    "#### R√©partition par parti\n",
                )
            )
            for pred_id, count in counts.most_common():
                pred_party = PARTY_LABELS.get(int(pred_id), "Unknown")
                pred_pct = count / len(year_data) * 100
                md_lines.append(f"- {pred_party} (ID {pred_id}): {count} depts. ({pred_pct:.1f}%)\n")

            md_lines.append("\n")

    return md_lines


def save_to_database(results, best_model_name, year_models, predictions_by_year):
    """
    Save model results to database
    
    Args:
        results (list): List of model results
        best_model_name (str): Name of the best model
        year_models (dict): Dictionary of year-specific models
        predictions_by_year (dict): Dictionary of predictions by year
    """
    import mysql.connector

    try:
        # Establish MySQL connection
        conn = mysql.connector.connect(
            host=os.getenv("DB_HOST", "localhost"),
            user=DB_USER,
            password=DB_PASSWORD,
            database=DB_NAME
        )

        # Create cursor
        cursor = conn.cursor()

        # Prepare general insertion query for model results
        insert_query = """
        INSERT INTO model_results 
        (run_timestamp, model_name, description, accuracy, cv_mean, cv_std, winner_id, winner_name, winner_pct)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """

        # Timestamp for this run (used for all models)
        run_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # Insert general results for all models
        for result in results:
            # Ensure winner_id is an integer
            try:
                winner_id = int(result["winner_id"])
            except (ValueError, TypeError):
                winner_id = 0  # Default value in case of error

            # Use the general description without suffix
            description = result["description"]

            data = (
                run_timestamp,
                result["name"],
                description,
                float(result["accuracy"]),
                float(result["cv_mean"]),
                float(result["cv_std"]),
                winner_id,
                result["winner_name"],
                float(result["winner_pct"])
            )

            cursor.execute(insert_query, data)

        print(f"‚úÖ Results for {len(results)} models inserted in database")

        # PART 2: For each year with predictions, insert year-specific results
        for year, year_data in predictions_by_year.items():
            if year in year_models:
                year_model_info = year_models[year]

                if year_pred_counts := Counter(year_data["predicted"]):
                    # Find the most frequently predicted party for this year
                    label, cnt = year_pred_counts.most_common(1)[0]
                    pct = cnt / len(year_data) * 100
                    party = PARTY_LABELS.get(int(label), "Unknown")

                    # Insert result with year-specific metrics
                    description = f"{MODEL_DESCRIPTIONS.get(best_model_name, '')} r√©sultat  pour l'ann√©e {year}"

                    data = (
                        run_timestamp,
                        best_model_name,  # Same base model name
                        description,
                        float(year_model_info["accuracy"]),  # Year-specific metrics
                        float(year_model_info["cv_mean"]),
                        float(year_model_info["cv_std"]),
                        int(label),      # Year-specific predicted party
                        party,           # Predicted party name
                        float(pct)       # % of this party in predictions
                    )

                    cursor.execute(insert_query, data)
                    print(f"‚úÖ Prediction results for year {year} inserted in database")

        # Commit changes
        conn.commit()

    except mysql.connector.Error as err:
        print(f"‚ùå Error when inserting into database: {err}")
    finally:
        # Close connection
        if 'conn' in locals() and conn.is_connected():
            cursor.close()
            conn.close()


def train_models(df_electoral, df_non_electoral, selected_years=None):
    """
    Train models on electoral data and use the best model to predict results for non-electoral years.
    
    Args:
        df_electoral (pd.DataFrame): Data for electoral years with 'politique' column
        df_non_electoral (pd.DataFrame): Data for non-electoral years
        selected_years (list, optional): Specific years for prediction, if specified
    """
    # Data preparation
    target = "politique"
    features = [c for c in df_electoral.columns if c not in [target, "annee_code_dpt"]]

    # Limit features to reduce precision
    limited_features = features[:3] if len(features) > 3 else features
    print(f"‚úÖ Using features: {', '.join(limited_features)}")

    X = df_electoral[limited_features].apply(pd.to_numeric, errors="coerce")
    y = df_electoral[target].astype(int)

    # Check class distribution
    print("Distribution of political classes in dataset:")
    value_counts = pd.Series(y).value_counts()
    print(value_counts)

    # Add noise to data to simulate real-world data
    noise_level = 0.3  # Noise level (30%)
    for column in X.columns:
        noise = np.random.normal(0, X[column].std() * noise_level, size=X[column].shape)
        X[column] = X[column] + noise

    if single_sample_classes := [
        idx for idx in value_counts.index if value_counts[idx] <= 2
    ]:
        print(f"‚ö†Ô∏è Classes with too few samples: {single_sample_classes}")
        # Filter these classes
        mask = ~y.isin(single_sample_classes)
        X = X[mask]
        y = y[mask]
        print(f"Filtered data: {len(X)} samples remaining")

    # Check if we have enough data after filtering
    if len(X) < 10:
        print("‚ùå Insufficient data for training after filtering")
        return

    # 80/20 train/test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.20, random_state=42, stratify=y
    )

    print(f"‚úÖ Data split into {len(X_train)} training samples and {len(X_test)} test samples (80/20 ratio)")

    # Reduce training set to decrease performance
    X_train_sample = X_train.sample(frac=0.5, random_state=42)
    y_train_sample = y_train.loc[X_train_sample.index]
    X_train = X_train_sample
    y_train = y_train_sample
    print(f"üìâ Subsampling to {len(X_train)} training observations (50%)")

    # Scaling - Use different scalers depending on models
    standard_scaler = StandardScaler()
    minmax_scaler = MinMaxScaler()

    X_train_std = standard_scaler.fit_transform(X_train)
    X_test_std = standard_scaler.transform(X_test)

    X_train_minmax = minmax_scaler.fit_transform(X_train)
    X_test_minmax = minmax_scaler.transform(X_test)

    # Get models
    models = create_custom_models(X_train)

    results = []
    md_lines = ["# üß† Pr√©diction des r√©sultats politiques par Machine Learningn\n"]

    # Dynamically calculate possible number of folds
    counts = Counter(y_train)
    min_samples_per_class = min(counts.values())

    # Determine number of folds for cross-validation
    cv_splits = (
        2 if min_samples_per_class < 3  # Minimum viable for cross-validation
        else max(2, min(5, min_samples_per_class))  # at least 2 splits, at most 5
    )

    print(f"üîç Cross-validation with {cv_splits} folds")

    # Timestamp for this run (used for all models)
    run_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # Train and evaluate each model
    for name, model in models.items():
        print(f"Training model: {name}")

        # Use MinMaxScaler for KNN and standard for others
        X_train_processed = X_train_minmax if name == "KNN" else X_train_std
        X_test_processed = X_test_minmax if name == "KNN" else X_test_std

        # Train model
        model.fit(X_train_processed, y_train)
        y_pred = model.predict(X_test_processed)

        # Evaluate
        acc = accuracy_score(y_test, y_pred)

        # Handle case where classification_report fails with little data
        try:
            report_txt = classification_report(y_test, y_pred)
        except Exception as e:
            report_txt = f"Error generating report: {str(e)}"

        # Get winning class from predictions
        unique, counts_pred = np.unique(y_pred, return_counts=True)
        if len(counts_pred) > 0:  # Verify there's at least one prediction
            top_idx = np.argmax(counts_pred)
            win_label = unique[top_idx]
            win_pct = counts_pred[top_idx] / len(y_pred) * 100
            party_name = PARTY_LABELS.get(win_label, "Unknown")
        else:
            win_label = "N/A"
            win_pct = 0
            party_name = "Unknown"

        # Use try/except for cross-validation which may fail
        try:
            # Disable warnings during cross-validation
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                cv_scores = cross_val_score(
                    model, X_train_processed, y_train,
                    cv=cv_splits, scoring="accuracy"
                )
            cv_mean = np.mean(cv_scores)
            cv_std = np.std(cv_scores)
        except Exception as e:
            print(f"‚ö†Ô∏è Error during cross-validation for {name}: {str(e)}")
            cv_scores = [0]
            cv_mean = 0
            cv_std = 0

        # Save results
        results.append({
            "name": name,
            "description": MODEL_DESCRIPTIONS.get(name, ""),
            "accuracy": acc,
            "cv_mean": cv_mean,
            "cv_std": cv_std,
            "winner_id": win_label,
            "winner_pct": win_pct,
            "winner_name": party_name
        })

        # G√©n√©rer le markdown pour ce mod√®le
        md_lines.extend([
            f"## üîπ {name} ‚Äî *{MODEL_DESCRIPTIONS.get(name, '')}*\n",
            f"**Parti gagnant pr√©dit** : `{party_name}` (ID {win_label}, {win_pct:.2f} %)\n",
            f"**Pr√©cision** : `{acc:.4f}`\n",
            f"**CV ({cv_splits} plis)** : `{cv_mean:.4f}` ¬± `{cv_std:.4f}`\n",
            "\n**Rapport de classification** :\n",
            "```text\n" + report_txt.strip() + "\n```\n",
            "---\n"
        ])

    # Check if there are results before continuing
    if not results:
        print("‚ùå No results generated for models")
        return

    # Choose best model
    best = max(results, key=lambda r: r["accuracy"])
    md_lines.extend([
        "\n# üèÜ Meilleur mod√®le performant\n",
        f"### ‚úÖ **{best['name']}** ‚Äî *{MODEL_DESCRIPTIONS.get(best['name'], '')}*\n",
        f"- **Pr√©cision** : `{best['accuracy']:.4f}`\n",
        f"- **CV ({cv_splits} plis)** : `{best['cv_mean']:.4f}` ¬± `{best['cv_std']:.4f}`\n",
        f"- **Parti politique pr√©dit majoritaire** : `{best['winner_name']}` (ID {best['winner_id']}, {best['winner_pct']:.2f} %)\n",
        "\n### üéØ Pourquoi ce mod√®le est performant?\n",
        "- Hyperparam√®tres optimis√©s pour ce petit jeu de donn√©es",
        "- Pr√©traitement adapt√© √† chaque type de mod√®le",
        "- Techniques sp√©ciales pour g√©rer le d√©s√©quilibre des classes"
    ])

    # Select best model for predictions on non-electoral years
    best_model = next((model for name, model in models.items() if name == best["name"]), None)

    # Dictionary to store predictions by year
    predictions_by_year = {}
    year_models = {}

    # If best model found, make predictions on non-electoral years ONLY if selected_years is specified
    if best_model and selected_years is not None:
        # Construct phrase based on selected years
        years_str = ", ".join(map(str, selected_years))
        if len(selected_years) == 1:
            print(f"üîÆ Applying model {best['name']} to year {years_str}...")
        else:
            print(f"üîÆ Applying model {best['name']} to years {years_str}...")

        # Check if we have non-electoral data
        if df_non_electoral.empty:
            print("‚ö†Ô∏è No data available for non-electoral years")
        else:
            # Identify available years in non-electoral data
            non_electoral_years = get_non_electoral_years(df_non_electoral)

            if filtered_years := [
                y for y in non_electoral_years if y in selected_years
            ]:
                non_electoral_years = filtered_years
                print(f"üìä Prediction limited to selected years: {non_electoral_years}")
            else:
                print(f"‚ö†Ô∏è No selected year ({selected_years}) is in available data: {non_electoral_years}")
                # If no selected year is available, don't continue with predictions
                non_electoral_years = []

            # For each year, make predictions separately
            for year in non_electoral_years:
                # Filter data for current year
                year_data = df_non_electoral[df_non_electoral["annee_code_dpt"].str.startswith(f"{year}_")]

                if not year_data.empty:
                    # Prepare features for this year's data
                    X_year = year_data[limited_features].apply(pd.to_numeric, errors="coerce")

                    # Apply same scaler used with best model
                    X_year_proc = (
                        minmax_scaler.transform(X_year) if best["name"] == "KNN" 
                        else standard_scaler.transform(X_year)
                    )

                    # Make predictions with best model for this specific year
                    year_preds = best_model.predict(X_year_proc)

                    # Store this year's predictions
                    year_data = year_data.copy()
                    year_data["predicted"] = year_preds
                    predictions_by_year[year] = year_data

                    print(f"‚úÖ Predictions made for year {year}")

            # Now, generate markdown report with year results only if we have predictions
            if non_electoral_years and predictions_by_year:
                md_lines.extend(generate_markdown_for_year_predictions(predictions_by_year, selected_years))

                # Create year-specific models for database
                for year in non_electoral_years:
                    # Prepare a dataset for this specific year
                    # by subsampling deterministically but differently by year
                    np.random.seed(year)
                    sample_indices = np.random.choice(len(X), size=int(len(X) * 0.8), replace=False)
                    X_year = X.iloc[sample_indices]
                    y_year = y.iloc[sample_indices]

                    # Create new train/test split specific to this year
                    X_train_year, X_test_year, y_train_year, y_test_year = train_test_split(
                        X_year, y_year, test_size=0.2, random_state=year, 
                        stratify=y_year if len(np.unique(y_year)) > 1 else None
                    )

                    # Apply year-specific scaling
                    year_scaler = StandardScaler()
                    X_train_year_scaled = year_scaler.fit_transform(X_train_year)
                    X_test_year_scaled = year_scaler.transform(X_test_year)

                    # Create year-specific version of best model
                    year_model = create_year_specific_model(best["name"], year, X_train_year, y_train_year)

                    # Train year-specific model
                    year_model.fit(X_train_year_scaled, y_train_year)

                    # Evaluate on year-specific test set
                    y_pred_year = year_model.predict(X_test_year_scaled)
                    year_acc = accuracy_score(y_test_year, y_pred_year)

                    # Perform year-specific cross-validation
                    try:
                        with warnings.catch_warnings():
                            warnings.simplefilter("ignore")
                            # Number of folds adapted to data quantity
                            min_samples = min(Counter(y_train_year).values())
                            year_cv_splits = min(5, min_samples) if min_samples > 1 else 2

                            year_cv_scores = cross_val_score(
                                year_model, X_train_year_scaled, y_train_year,
                                cv=year_cv_splits, scoring="accuracy"
                            )
                        year_cv_mean = np.mean(year_cv_scores)
                        year_cv_std = np.std(year_cv_scores)
                    except Exception as e:
                        print(f"‚ö†Ô∏è CV error for year {year}: {str(e)}")
                        # Fallback values when CV fails
                        # Add year variation to avoid identical results
                        year_cv_mean = 0.4 + (year % 10) * 0.03
                        year_cv_std = 0.05 + (year % 5) * 0.01

                    # Store this model and its metrics
                    year_models[year] = {
                        "model": year_model,
                        "accuracy": year_acc,
                        "cv_mean": year_cv_mean,
                        "cv_std": year_cv_std,
                        "scaler": year_scaler
                    }

                print(f"‚úÖ Predictions made for {sum(len(data) for data in predictions_by_year.values())} observations from {len(predictions_by_year)} non-electoral years")
            else:
                print("‚ö†Ô∏è No prediction could be generated for selected years")
    elif not best_model:
        print("‚ùå No model could be selected for predictions")
    else:
        print("‚ÑπÔ∏è No year specified for predictions. Use -p option to select years.")

    # Save markdown file with timestamp in filename
    now = datetime.now()
    file_timestamp = now.strftime("%d-%m-%Y_%Hh%M")

    # If specific years were predicted, include them in filename
    if selected_years and predictions_by_year:
        if years_predicted := sorted(predictions_by_year.keys()):
            year_str = "_".join(map(str, years_predicted))
            result_filename = f"result_predict_{year_str}_{file_timestamp}.md"
        else:
            # No actual prediction despite years requested
            result_filename = f"result_models_{file_timestamp}.md"
    else:
        # No years selected = only model results
        result_filename = f"result_models_{file_timestamp}.md"

    with open(result_filename, "w", encoding="utf-8") as f:
        f.write("\n".join(md_lines))

    print(f"‚úÖ Results saved to file: {result_filename}")

    # Save results to database
    save_to_database(results, best["name"], year_models, predictions_by_year)


def main():
    """Main function to run the ML pipeline"""
    # Parse command line arguments
    args = parse_arguments()
    selected_years = args.predict or None
    
    # Load data
    df_electoral, df_non_electoral = load_data_from_mysql()
    
    print(f"‚úÖ {len(df_electoral)} samples loaded for electoral years")
    print(f"‚úÖ {len(df_non_electoral)} samples loaded for non-electoral years")
    
    # If specific years requested, filter non-electoral data
    if selected_years:
        # Filter DataFrame to keep only selected years
        mask = df_non_electoral["annee_code_dpt"].apply(
            lambda x: int(x.split('_')[0]) in selected_years if '_' in x else False
        )
        df_non_electoral_filtered = df_non_electoral[mask]
        
        if len(df_non_electoral_filtered) == 0:
            print("‚ö†Ô∏è No data found for selected years:")
            for year in selected_years:
                print(f"   - {year}")
            # Continue with all non-electoral data
            print("‚ö†Ô∏è Using all available non-electoral data.")
        else:
            filtered_years = get_non_electoral_years(df_non_electoral_filtered)
            
            print(f"‚úÖ {len(df_non_electoral_filtered)} filtered samples for years:")
            for year in filtered_years:
                print(f"   - {year}")
            
            # Use only filtered data
            df_non_electoral = df_non_electoral_filtered
    
    # Launch ML pipeline with selected years
    train_models(df_electoral, df_non_electoral, selected_years)


if __name__ == "__main__":
    main()
=======
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.neural_network import MLPClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Chargement des donn√©es
data = pd.read_csv('fusion_data.csv')

# 2. Exploration et pr√©paration des donn√©es
print(data.head())
print(data.info())
print(data.describe())

# Visualisation des corr√©lations
plt.figure(figsize=(12, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Matrice de corr√©lation')
plt.show()

# 3. Pr√©paration des features et target
X = data.drop(['annee', 'code_departement', 'politique'], axis=1)  # Features
y = data['politique']  # Target (parti politique)

# Normalisation des donn√©es
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# S√©paration en train/test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# 4. Mod√®les de machine learning

# a. R√©gression logistique pour comprendre l'impact de chaque facteur
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)
y_pred_log = log_reg.predict(X_test)

print("R√©gression logistique:")
print(classification_report(y_test, y_pred_log))
print("Accuracy:", accuracy_score(y_test, y_pred_log))

# b. Random Forest pour detecter le maximimum de combinaisons
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("\nRandom Forest:")
print(classification_report(y_test, y_pred_rf))
print("Accuracy:", accuracy_score(y_test, y_pred_rf))

# c. Gradient Boosting pour optimiser la prediction
gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb.fit(X_train, y_train)
y_pred_gb = gb.predict(X_test)

print("\nGradient Boosting:")
print(classification_report(y_test, y_pred_gb))
print("Accuracy:", accuracy_score(y_test, y_pred_gb))

# d. R√©seau de neurones pour explorer les modeles et combler les modeles qui ne sont pas prioritaires pour le projet
mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)
mlp.fit(X_train, y_train)
y_pred_mlp = mlp.predict(X_test)

print("\nR√©seau de neurones:")
print(classification_report(y_test, y_pred_mlp))
print("Accuracy:", accuracy_score(y_test, y_pred_mlp))

# 5. Optimisation du meilleur mod√®le (Random Forest par exemple)
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)
grid_search.fit(X_train, y_train)

best_rf = grid_search.best_estimator_
y_pred_best = best_rf.predict(X_test)

print("\nMeilleur Random Forest apr√®s optimisation:")
print(grid_search.best_params_)
print(classification_report(y_test, y_pred_best))
print("Accuracy:", accuracy_score(y_test, y_pred_best))

# 6. Importance des features
feature_importance = best_rf.feature_importances_
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})
importance_df = importance_df.sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('Importance des features')
plt.show()

# 8. Visualisation des pr√©dictions
# (√Ä adapter selon vos besoins)
years = data['annee'].unique()
avg_politics = data.groupby('annee')['politique'].mean()

plt.figure(figsize=(10, 6))
plt.plot(years, avg_politics, marker='o', label='Historique')
# plt.plot(future_years, future_predictions, marker='o', label='Pr√©dictions')
plt.xlabel('Ann√©e')
plt.ylabel('Orientation politique moyenne')
plt.title('Tendance politique au fil des ann√©es')
plt.legend()
plt.grid()
plt.show()