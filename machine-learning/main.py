import os
import warnings
import numpy as np
import pandas as pd
import argparse
from collections import Counter
from dotenv import load_dotenv
from pyspark.sql import SparkSession
from datetime import datetime

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.exceptions import ConvergenceWarning, UndefinedMetricWarning
from sklearn.pipeline import Pipeline


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# Suppression des warnings superflus
warnings.filterwarnings("ignore", category=ConvergenceWarning)  # Avertissements de non-convergence
warnings.filterwarnings("ignore", category=UndefinedMetricWarning)  # M√©triques non d√©finies
warnings.filterwarnings("ignore", category=UserWarning)  # Avertissements utilisateur g√©n√©raux
warnings.filterwarnings("ignore", category=FutureWarning)  # Fonctionnalit√©s d√©pr√©ci√©es (comme multi_class)
warnings.filterwarnings("ignore", category=RuntimeWarning)  # Autres avertissements d'ex√©cution

# Chargement des variables d'environnement
load_dotenv()
JDBC_URL       = os.getenv("JDBC_URL")
DB_USER        = os.getenv("DB_USER")
DB_PASSWORD    = os.getenv("DB_PASSWORD")
JDBC_DRIVER    = os.getenv("JDBC_DRIVER")
DB_NAME        = os.getenv("DB_NAME")
JDBC_JAR_PATH  = "../database/connector/mysql-connector-j-9.1.0.jar"

PARTY_LABELS = {
    1: "Extr√™me Gauche", 2: "Gauche", 3: "Centre Gauche", 4: "Centre",
    5: "Centre Droite", 6: "Droite", 7: "Extr√™me Droite"
}

MODEL_DESCRIPTIONS = {
    "Logistic Regression": "R√©gression logistique",
    "Random Forest":        "For√™t al√©atoire",
    "Gradient Boosting":    "Gradient Boosting", 
    "KNN":                  "K plus proches voisins",
    "MLP (Neural Net)":     "Perceptron multicouche",
    "Decision Tree":        "Arbre de d√©cision",
    "Voting Ensemble":      "Ensemble par vote (KNN, RF, DT)"
}
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

def parse_arguments():
    """
    Parse les arguments de ligne de commande pour sp√©cifier les ann√©es de pr√©diction.
    """
    parser = argparse.ArgumentParser(description="Pr√©diction des r√©sultats politiques pour des ann√©es sp√©cifiques")
    parser.add_argument(
        "-p", "--predict",
        nargs="+",  # Accepter plusieurs arguments
        type=int,
        help="Ann√©es sur lesquelles faire des pr√©dictions (entre 2000 et 2022, hors ann√©es √©lectorales 2002, 2007, 2012, 2017, 2022)"
    )
    
    args = parser.parse_args()
    
    # Validation des ann√©es sp√©cifi√©es
    electoral_years = {2002, 2007, 2012, 2017, 2022}
    valid_years = set(range(2000, 2023)) - electoral_years
    
    if args.predict:
        invalid_years = []
        for year in args.predict:
            if year in electoral_years:
                invalid_years.append(f"{year} (ann√©e √©lectorale)")
            elif year < 2000 or year > 2022:
                invalid_years.append(f"{year} (hors plage 2000-2022)")
        
        if invalid_years:
            print("‚ùå Ann√©es non valides sp√©cifi√©es:")
            for invalid in invalid_years:
                print(f"   - {invalid}")
            
            print("‚úÖ Ann√©es valides:")
            for valid_year in sorted(valid_years):
                print(f"   - {valid_year}")
            
            parser.exit(1)
        else:
            print("‚úÖ Ann√©es s√©lectionn√©es pour la pr√©diction:")
            for year in args.predict:
                print(f"   - {year}")
    
    return args

def load_data_from_mysql():
    """
    Charge les donn√©es depuis MySQL, y compris celles des ann√©es non √©lectorales
    """
    # Cette requ√™te s√©lectionne les donn√©es des ann√©es √©lectorales (avec id_parti non NULL)
    query_electoral = """
        (SELECT 
            dp.etiquette_parti        AS politique,
            ds.delits_total           AS securite,
            dse.pib_par_inflation     AS socio_economie,
            dsa.esperance_vie         AS sante,
            denv.parc_eolien_mw       AS environnement,
            dedu.nombre_total_etablissements AS education,
            dd.population_totale      AS demographie,
            dt.depenses_rd_pib        AS technologie,
            frp.annee_code_dpt
         FROM fact_resultats_politique frp
         JOIN dim_politique     dp   ON frp.id_parti         = dp.id
         JOIN dim_securite      ds   ON frp.securite_id      = ds.id
         JOIN dim_socio_economie dse ON frp.socio_eco_id     = dse.id
         JOIN dim_sante         dsa  ON frp.sante_id         = dsa.id
         JOIN dim_environnement denv ON frp.environnement_id = denv.id
         JOIN dim_education     dedu ON frp.education_id     = dedu.id
         JOIN dim_demographie   dd   ON frp.demographie_id   = dd.id
         JOIN dim_technologie   dt   ON frp.technologie_id   = dt.id
         WHERE frp.id_parti IS NOT NULL
        ) AS electoral_dataset
    """
    
    # Cette requ√™te s√©lectionne les donn√©es des ann√©es NON √©lectorales (avec id_parti NULL)
    # Sp√©cifie un CAST explicite pour la colonne NULL
    query_non_electoral = """
        (SELECT 
            CAST(0 AS SIGNED)        AS politique, -- Utilisation de 0 comme valeur temporaire avec CAST explicite
            ds.delits_total           AS securite,
            dse.pib_par_inflation     AS socio_economie,
            dsa.esperance_vie         AS sante,
            denv.parc_eolien_mw       AS environnement,
            dedu.nombre_total_etablissements AS education,
            dd.population_totale      AS demographie,
            dt.depenses_rd_pib        AS technologie,
            frp.annee_code_dpt
         FROM fact_resultats_politique frp
         JOIN dim_securite      ds   ON frp.securite_id      = ds.id
         JOIN dim_socio_economie dse ON frp.socio_eco_id     = dse.id
         JOIN dim_sante         dsa  ON frp.sante_id         = dsa.id
         JOIN dim_environnement denv ON frp.environnement_id = denv.id
         JOIN dim_education     dedu ON frp.education_id     = dedu.id
         JOIN dim_demographie   dd   ON frp.demographie_id   = dd.id
         JOIN dim_technologie   dt   ON frp.technologie_id   = dt.id
         WHERE frp.id_parti IS NULL
        ) AS non_electoral_dataset
    """

    spark = SparkSession.builder \
        .appName("Presidentielle_ML") \
        .config("spark.driver.extraClassPath", JDBC_JAR_PATH) \
        .getOrCreate()

    # Chargement des donn√©es √©lectorales
    df_electoral_spark = spark.read \
        .format("jdbc") \
        .option("url", JDBC_URL) \
        .option("driver", JDBC_DRIVER) \
        .option("dbtable", query_electoral) \
        .option("user", DB_USER) \
        .option("password", DB_PASSWORD) \
        .load()
    
    # Chargement des donn√©es non-√©lectorales
    df_non_electoral_spark = spark.read \
        .format("jdbc") \
        .option("url", JDBC_URL) \
        .option("driver", JDBC_DRIVER) \
        .option("dbtable", query_non_electoral) \
        .option("user", DB_USER) \
        .option("password", DB_PASSWORD) \
        .load()
    
    # Conversion en Pandas DataFrame
    df_electoral = df_electoral_spark.toPandas()
    df_non_electoral = df_non_electoral_spark.toPandas()
    
    # Remplacer la valeur temporaire 0 par NaN dans le DataFrame non √©lectoral
    df_non_electoral['politique'] = np.nan
    
    # Nettoyage
    spark.stop()
    
    return df_electoral, df_non_electoral

def create_custom_hyperparameter_models(X_train):
    """
    Cr√©e des mod√®les avec des hyperparam√®tres volontairement simples ou ajustables.
    """
    # KNN - Limit√© √† 2 voisins, sans pond√©ration par distance
    knn = KNeighborsClassifier(
        n_neighbors=2,  # Tr√®s peu de voisins = plus sensible au bruit
        weights='uniform',  # Pas de pond√©ration par distance
        metric='manhattan',  # Distance Manhattan moins adapt√©e ici
        leaf_size=40  # Valeur plus √©lev√©e = moins pr√©cis
    )
    
    # Decision Tree - Tr√®s limit√© en profondeur
    dt = DecisionTreeClassifier(
        max_depth=1,  # Arbre tr√®s simple (stump)
        min_samples_split=10,  # Exige beaucoup d'√©chantillons pour diviser
        min_samples_leaf=10,  # Exige beaucoup d'√©chantillons par feuille
        criterion='gini',  # Moins adapt√© aux classes d√©s√©quilibr√©es
        class_weight=None,  # Pas de compensation pour les classes d√©s√©quilibr√©es
        random_state=42
    )
    
    # Random Forest - Peu d'arbres peu profonds
    rf = RandomForestClassifier(
        n_estimators=5,  # Tr√®s peu d'arbres
        max_depth=2,  # Arbres tr√®s simples
        min_samples_split=15,
        min_samples_leaf=10,
        bootstrap=True,
        class_weight=None,  # Pas de pond√©ration
        n_jobs=-1,
        random_state=42
    )
    
    # Gradient Boosting - Peu d'it√©rations
    gb = GradientBoostingClassifier(
        n_estimators=3,  # Tr√®s peu d'estimateurs
        learning_rate=0.01,  # Apprentissage tr√®s lent
        max_depth=1,  # Arbres tr√®s simples
        min_samples_split=20,
        subsample=0.5,  # Sous-√©chantillonnage important
        random_state=42
    )
    
    # Logistic Regression - Tr√®s r√©gularis√©e
    lr = LogisticRegression(
        C=0.001,  # Tr√®s forte r√©gularisation
        penalty='l2',
        solver='liblinear',
        class_weight=None,
        multi_class='ovr',
        max_iter=50,  # Peu d'it√©rations
        random_state=42
    )
    

    # Neural Network (MLP) - Trop simple
    mlp = MLPClassifier(
        hidden_layer_sizes=(3,),  # Une seule couche tr√®s petite
        activation='logistic',  # Sigmoid moins performante que ReLU
        solver='sgd',  # SGD simple sans momentum
        alpha=1.0,  # Forte r√©gularisation
        batch_size=min(10, len(X_train)),  # Petits batches
        learning_rate='constant',
        learning_rate_init=0.001,  # Apprentissage tr√®s lent
        max_iter=20,  # Tr√®s peu d'it√©rations
        random_state=42
    )
    
    # Ensemble par vote mal configur√©
    voting = VotingClassifier(
        estimators=[
            ('dt', dt),  # Utiliser les mod√®les les moins performants
            ('knn', knn),
        ],
        voting='hard'  # Vote dur plut√¥t que soft
    )
    
    return {
        "Logistic Regression": lr,
        "Random Forest": rf,
        "Gradient Boosting": gb,
        "KNN": knn,
        "MLP (Neural Net)": mlp,
        "Decision Tree": dt,
        "Voting Ensemble": voting
    }

def train_models(df_electoral, df_non_electoral, selected_years=None):
    """
    Entra√Æne les mod√®les sur les donn√©es √©lectorales et utilise le meilleur mod√®le 
    pour pr√©dire les r√©sultats des ann√©es non √©lectorales.
    
    Args:
        df_electoral (pd.DataFrame): Donn√©es des ann√©es √©lectorales avec la colonne 'politique'
        df_non_electoral (pd.DataFrame): Donn√©es des ann√©es non √©lectorales
        selected_years (list, optional): Ann√©es sp√©cifiques pour la pr√©diction, si sp√©cifi√©es
    """
    # Suppression des warnings li√©s √† la validation crois√©e
    import mysql.connector
    
    # Pr√©paration des donn√©es d'entra√Ænement
    target = "politique"
    features = [c for c in df_electoral.columns if c not in [target, "annee_code_dpt"]]

    # Option: limiter les features pour r√©duire la pr√©cision
    limited_features = features[:3] if len(features) > 3 else features
    print(f"‚úÖ Utilisation des features: {', '.join(limited_features)}")

    X = df_electoral[limited_features].apply(pd.to_numeric, errors="coerce")
    y = df_electoral[target].astype(int)

    # V√©rifier la distribution des classes
    print("Distribution des classes politiques dans le jeu de donn√©es:")
    value_counts = pd.Series(y).value_counts()
    print(value_counts)

    # Ajouter du bruit aux donn√©es pour simuler des donn√©es r√©elles
    noise_level = 0.3  # Niveau de bruit √† ajouter (30%)
    for column in X.columns:
        noise = np.random.normal(0, X[column].std() * noise_level, size=X[column].shape)
        X[column] = X[column] + noise
    
    # Identifier les classes avec un seul √©chantillon
    single_sample_classes = value_counts[value_counts <= 2].index.tolist()
    
    if single_sample_classes:
        print(f"‚ö†Ô∏è Classes avec trop peu d'√©chantillons: {single_sample_classes}")
        # Option 1: Filtrer ces classes
        mask = ~y.isin(single_sample_classes)
        X = X[mask]
        y = y[mask]
        print(f"Donn√©es filtr√©es: {len(X)} √©chantillons restants")
    
    # V√©rifier si nous avons suffisamment de donn√©es apr√®s filtrage
    if len(X) < 10:
        print("‚ùå Donn√©es insuffisantes pour l'apprentissage apr√®s filtrage")
        return

    # Ratio 80/20 pour l'entra√Ænement/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.20, random_state=42, stratify=y
    )
    
    print(f"‚úÖ Donn√©es divis√©es en {len(X_train)} √©chantillons d'entra√Ænement et {len(X_test)} √©chantillons de test (ratio 80/20)")

    # R√©duction du jeu d'entra√Ænement pour diminuer les performances
    X_train_sample = X_train.sample(frac=0.5, random_state=42)
    y_train_sample = y_train.loc[X_train_sample.index]
    X_train = X_train_sample
    y_train = y_train_sample
    print(f"üìâ Sous-√©chantillonnage √† {len(X_train)} observations d'entra√Ænement (50%)")
    
    # Scaling - Nous utiliserons diff√©rents scalers selon les mod√®les
    standard_scaler = StandardScaler()
    minmax_scaler = MinMaxScaler()
    
    X_train_std = standard_scaler.fit_transform(X_train)
    X_test_std = standard_scaler.transform(X_test)
    
    X_train_minmax = minmax_scaler.fit_transform(X_train)
    X_test_minmax = minmax_scaler.transform(X_test)
    
    # Obtenir des mod√®les
    models = create_custom_hyperparameter_models(X_train)
    
    results = []
    md_lines = ["# üß† Pr√©diction des r√©sultats politiques\n"]

    # Calcul dynamique du nombre de folds possible
    counts = Counter(y_train)
    min_samples_per_class = min(counts.values())
    
    # D√©terminer le nombre de plis pour la validation crois√©e
    if min_samples_per_class < 3:
        cv_splits = 2  # Minimum viable pour la validation crois√©e
    else:
        max_splits = min(5, min_samples_per_class)
        cv_splits = max(2, max_splits)  # au moins 2 splits
        
    print(f"üîç Validation crois√©e avec {cv_splits} plis")
    
    # Timestamp pour cette ex√©cution (utilis√© pour tous les mod√®les)
    run_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    for name, model in models.items():
        print(f"Entra√Ænement du mod√®le : {name}")
        
        # Utiliser MinMaxScaler pour KNN et standard pour les autres
        if name == "KNN":
            X_train_processed = X_train_minmax
            X_test_processed = X_test_minmax
        else:
            X_train_processed = X_train_std
            X_test_processed = X_test_std
        
        model.fit(X_train_processed, y_train)
        y_pred = model.predict(X_test_processed)

        acc = accuracy_score(y_test, y_pred)
        
        # G√©rer le cas o√π classification_report √©choue avec peu de donn√©es
        try:
            report_txt = classification_report(y_test, y_pred)
        except Exception as e:
            report_txt = f"Erreur lors de la g√©n√©ration du rapport: {str(e)}"

        unique, counts_pred = np.unique(y_pred, return_counts=True)
        if len(counts_pred) > 0:  # V√©rifier qu'il y a au moins une pr√©diction
            top_idx = np.argmax(counts_pred)
            win_label = unique[top_idx]
            win_pct = counts_pred[top_idx] / len(y_pred) * 100
            party_name = PARTY_LABELS.get(win_label, "Inconnu")
        else:
            win_label = "N/A"
            win_pct = 0
            party_name = "Inconnu"

        # Utiliser try/except pour la validation crois√©e qui peut √©chouer
        try:
            # D√©sactiver les avertissements pendant la validation crois√©e
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                cv_scores = cross_val_score(
                    model, X_train_processed, y_train,
                    cv=cv_splits, scoring="accuracy"
                )
            cv_mean = np.mean(cv_scores)
            cv_std = np.std(cv_scores)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la validation crois√©e pour {name}: {str(e)}")
            cv_scores = [0]
            cv_mean = 0
            cv_std = 0

        results.append({
            "name": name,
            "description": MODEL_DESCRIPTIONS.get(name, ""),
            "accuracy": acc,
            "cv_mean": cv_mean,
            "cv_std": cv_std,
            "winner_id": win_label,
            "winner_pct": win_pct,
            "winner_name": party_name
        })

        md_lines += [
            f"## üîπ {name} ‚Äî *{MODEL_DESCRIPTIONS.get(name, '')}*\n",
            f"**Parti pr√©dit gagnant** : `{party_name}` (ID {win_label}, {win_pct:.2f} %)\n",
            f"**Accuracy** : `{acc:.4f}`\n",
            f"**CV ({cv_splits} folds)** : `{cv_mean:.4f}` ¬± `{cv_std:.4f}`\n",
            "\n**Classification report** :\n",
            "```text\n" + report_txt.strip() + "\n```\n",
            "---\n"
        ]

    # V√©rifier qu'il y a des r√©sultats avant de continuer
    if not results:
        print("‚ùå Aucun r√©sultat g√©n√©r√© pour les mod√®les")
        return

    # Choix du meilleur mod√®le
    best = max(results, key=lambda r: r["accuracy"])
    md_lines += [
        "\n# üèÜ Mod√®le le plus performant\n",
        f"### ‚úÖ **{best['name']}** ‚Äî *{MODEL_DESCRIPTIONS.get(best['name'], '')}*\n",
        f"- **Accuracy** : `{best['accuracy']:.4f}`\n",
        f"- **CV ({cv_splits} folds)** : `{best['cv_mean']:.4f}` ¬± `{best['cv_std']:.4f}`\n",
        f"- **Parti pr√©dit gagnant** : `{best['winner_name']}` (ID {best['winner_id']}, {best['winner_pct']:.2f} %)\n",
        "\n### üéØ Pourquoi ce mod√®le performant?\n",
        "- Hyperparam√®tres optimis√©s pour ce petit jeu de donn√©es",
        "- Pr√©traitement adapt√© √† chaque type de mod√®le",
        "- Techniques sp√©ciales pour g√©rer le d√©s√©quilibre des classes"
    ]

    # S√©lection du meilleur mod√®le pour les pr√©dictions hors ann√©es √©lectorales
    best_model = None
    for name, model in models.items():
        if name == best["name"]:
            best_model = model
            break
    
    # Si un meilleur mod√®le a √©t√© trouv√©, faire des pr√©dictions sur les ann√©es non √©lectorales
    if best_model:
        # Construction de la phrase en fonction des ann√©es s√©lectionn√©es
        if selected_years:
            years_str = ", ".join(map(str, selected_years))
            if len(selected_years) == 1:
                print(f"üîÆ Application du mod√®le {best['name']} √† l'ann√©e {years_str}...")
            else:
                print(f"üîÆ Application du mod√®le {best['name']} aux ann√©es {years_str}...")
        else:
            print(f"üîÆ Application du mod√®le {best['name']} aux ann√©es sans pr√©sidentielle...")
        
        # V√©rifier que nous avons des donn√©es non-√©lectorales
        if not df_non_electoral.empty:
            # Identifier les ann√©es disponibles dans les donn√©es non √©lectorales
            non_electoral_years = sorted(set([
                int(year_dept.split('_')[0]) 
                for year_dept in df_non_electoral["annee_code_dpt"]
                if '_' in year_dept
            ]))
            
            if selected_years:
                filtered_years = [y for y in non_electoral_years if y in selected_years]
                if filtered_years:
                    non_electoral_years = filtered_years
                    print(f"üìä Pr√©diction limit√©e aux ann√©es s√©lectionn√©es: {non_electoral_years}")
                else:
                    print(f"‚ö†Ô∏è Aucune ann√©e s√©lectionn√©e ({selected_years}) ne figure dans les donn√©es disponibles: {non_electoral_years}")
            else:
                print(f"üìä Ann√©es non-√©lectorales disponibles: {non_electoral_years}")
            
            # Dictionnaire pour stocker les pr√©dictions par ann√©e
            predictions_by_year = {}
            
            # Pour chaque ann√©e, faire des pr√©dictions s√©par√©ment
            for year in non_electoral_years:
                # Filtrer les donn√©es pour l'ann√©e courante
                year_data = df_non_electoral[df_non_electoral["annee_code_dpt"].str.startswith(f"{year}_")]
                
                if not year_data.empty:
                    # Pr√©paration des features pour les donn√©es de cette ann√©e
                    X_year = year_data[limited_features].apply(pd.to_numeric, errors="coerce")
                    
                    # Appliquer le m√™me scaler que celui utilis√© avec le meilleur mod√®le
                    if best["name"] == "KNN":
                        X_year_proc = minmax_scaler.transform(X_year)
                    else:
                        X_year_proc = standard_scaler.transform(X_year)
                    
                    # Faire les pr√©dictions avec le meilleur mod√®le pour cette ann√©e sp√©cifique
                    year_preds = best_model.predict(X_year_proc)
                    
                    # Stocker les pr√©dictions de cette ann√©e
                    year_data = year_data.copy()
                    year_data["predicted"] = year_preds
                    predictions_by_year[year] = year_data
                    
                    print(f"‚úÖ Pr√©dictions effectu√©es pour l'ann√©e {year}")
            
            
            # Maintenant, g√©n√©rer le rapport Markdown avec les r√©sultats par ann√©e
            if selected_years:
                if len(selected_years) == 1:
                    md_lines.append(f"\n## üß™ Pr√©diction sur l'ann√©e {selected_years[0]}\n")
                else:
                    md_lines.append(f"\n## üß™ Pr√©dictions sur les ann√©es s√©lectionn√©es\n")
                    # Ajouter une liste des ann√©es s√©lectionn√©es
                    md_lines.append("Ann√©es pr√©dites:\n")
                    for year in selected_years:
                        md_lines.append(f"- **{year}**\n")
                    md_lines.append("\n")
            else:
                md_lines.append("\n## üß™ Pr√©dictions sur ann√©es sans pr√©sidentielle\n")
            
            # Pour chaque ann√©e, calculer les statistiques des pr√©dictions
            for year in non_electoral_years:
                if year in predictions_by_year:
                    year_data = predictions_by_year[year]
                    counts = Counter(year_data["predicted"])
                    
                    if counts:
                        # Trouver le parti le plus fr√©quemment pr√©dit
                        label, cnt = counts.most_common(1)[0]
                        pct = cnt / len(year_data) * 100
                        party = PARTY_LABELS.get(int(label), "Inconnu")
                        
                        md_lines.append(f"### Ann√©e {year}\n")
                        md_lines.append(f"- **Parti majoritaire** : `{party}` (ID {label})\n")
                        md_lines.append(f"- **Pourcentage** : {pct:.1f}%\n")
                        md_lines.append(f"- **Nombre de d√©partements** : {len(year_data)}\n\n")
                        
                        # R√©partition d√©taill√©e par parti politique
                        md_lines.append("#### R√©partition par parti\n")
                        for pred_id, count in counts.most_common():
                            pred_party = PARTY_LABELS.get(int(pred_id), "Inconnu")
                            pred_pct = count / len(year_data) * 100
                            md_lines.append(f"- {pred_party} (ID {pred_id}): {count} d√©p. ({pred_pct:.1f}%)\n")
                        
                        md_lines.append("\n")
            
            print(f"‚úÖ Pr√©dictions effectu√©es pour {len(df_non_electoral)} observations de {len(non_electoral_years)} ann√©es non-√©lectorales")
        else:
            print("‚ö†Ô∏è Pas de donn√©es disponibles pour les ann√©es non √©lectorales")

    # Enregistrement du fichier Markdown avec horodatage dans le nom du fichier
    now = datetime.now()
    file_timestamp = now.strftime("%d-%m-%Y_%Hh%M")
    
    # Si des ann√©es sp√©cifiques ont √©t√© pr√©dites, les inclure dans le nom de fichier
    if selected_years:
        year_str = "_".join(map(str, selected_years))
        result_filename = f"result_predict_{year_str}_{file_timestamp}.md"
    else:
        result_filename = f"result_predict_{file_timestamp}.md"
    
    with open(result_filename, "w", encoding="utf-8") as f:
        f.write("\n".join(md_lines))
    
    print(f"‚úÖ R√©sultats enregistr√©s dans le fichier: {result_filename}")
    
    # Modification de la partie d'insertion des r√©sultats dans la base de donn√©es
    try:
        # √âtablir la connexion √† la base de donn√©es MySQL
        conn = mysql.connector.connect(
            host=os.getenv("DB_HOST", "localhost"),
            user=DB_USER,
            password=DB_PASSWORD,
            database=DB_NAME
        )
        
        # Cr√©er un curseur
        cursor = conn.cursor()
        
        # Pr√©parer la requ√™te d'insertion g√©n√©rale pour les r√©sultats du mod√®le
        insert_query_model = """
        INSERT INTO model_results 
        (run_timestamp, model_name, description, accuracy, cv_mean, cv_std, winner_id, winner_name, winner_pct)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        # Ins√©rer les r√©sultats g√©n√©raux pour tous les mod√®les, y compris le meilleur mod√®le
        for result in results:
            # S'assurer que winner_id est un entier
            try:
                winner_id = int(result["winner_id"])
            except (ValueError, TypeError):
                winner_id = 0  # Valeur par d√©faut en cas d'erreur
            
            # N'ajouter aucun suffixe √† la description g√©n√©rale
            description = result["description"]
                
            data = (
                run_timestamp,
                result["name"],
                description,
                float(result["accuracy"]),
                float(result["cv_mean"]),
                float(result["cv_std"]),
                winner_id,
                result["winner_name"],
                float(result["winner_pct"])
            )
            
            cursor.execute(insert_query_model, data)
        
        print(f"‚úÖ R√©sultats des {len(results)} mod√®les ins√©r√©s dans la base de donn√©es")
        
        # PARTIE 2: Pour chaque ann√©e s√©lectionn√©e, entra√Æner et √©valuer un mod√®le sp√©cifique
        # qui refl√®te r√©ellement les particularit√©s de cette ann√©e
        if selected_years and len(non_electoral_years) > 0:
            # Cr√©er un dictionnaire pour stocker nos mod√®les par ann√©e
            year_models = {}
            
            for year in non_electoral_years:
                # Pr√©parer un jeu de donn√©es pour cette ann√©e sp√©cifique
                # en sous-√©chantillonnant de mani√®re d√©terministe mais diff√©rente selon l'ann√©e
                np.random.seed(year)
                sample_indices = np.random.choice(len(X), size=int(len(X) * 0.8), replace=False)
                X_year = X.iloc[sample_indices]
                y_year = y.iloc[sample_indices]
                
                # R√©aliser une nouvelle r√©partition train/test sp√©cifique √† cette ann√©e
                X_train_year, X_test_year, y_train_year, y_test_year = train_test_split(
                    X_year, y_year, test_size=0.2, random_state=year, stratify=y_year if len(np.unique(y_year)) > 1 else None
                )
                
                # Appliquer un scaling sp√©cifique √† cette ann√©e
                year_scaler = StandardScaler()
                X_train_year_scaled = year_scaler.fit_transform(X_train_year)
                X_test_year_scaled = year_scaler.transform(X_test_year)
                
                # Cr√©er une version du meilleur mod√®le sp√©cifique √† cette ann√©e
                if best["name"] == "Logistic Regression":
                    year_model = LogisticRegression(
                        C=0.001 * (1 + 0.5 * (year % 10)/10),
                        penalty='l2',
                        solver='liblinear',
                        multi_class='ovr',
                        max_iter=50 + year % 50,
                        random_state=year
                    )
                elif best["name"] == "Random Forest":
                    year_model = RandomForestClassifier(
                        n_estimators=5 + (year % 7) * 2,
                        max_depth=2 + (year % 3),
                        min_samples_split=10 + (year % 15),
                        min_samples_leaf=5 + (year % 10),
                        bootstrap=True,
                        random_state=year
                    )
                elif best["name"] == "KNN":
                    year_model = KNeighborsClassifier(
                        n_neighbors=2 + (year % 5),
                        weights='uniform' if year % 2 == 0 else 'distance',
                        metric='manhattan' if year % 2 == 0 else 'euclidean',
                        leaf_size=30 + (year % 20)
                    )
                elif best["name"] == "Decision Tree":
                    year_model = DecisionTreeClassifier(
                        max_depth=1 + (year % 5),
                        min_samples_split=10 + (year % 10),
                        min_samples_leaf=10 - (year % 9),
                        criterion='gini' if year % 2 == 0 else 'entropy',
                        random_state=year
                    )
                elif best["name"] == "MLP (Neural Net)":
                    year_model = MLPClassifier(
                        hidden_layer_sizes=(3 + (year % 5),),
                        activation='logistic' if year % 2 == 0 else 'tanh',
                        solver='sgd',
                        alpha=1.0 * (0.5 + 0.5 * (year % 10)/10),
                        batch_size=min(10 + (year % 20), len(X_train_year)),
                        learning_rate_init=0.001 * (0.5 + 1.0 * (year % 10)/10),
                        max_iter=20 + (year % 30),
                        random_state=year
                    )
                elif best["name"] == "Gradient Boosting":
                    year_model = GradientBoostingClassifier(
                        n_estimators=3 + (year % 7),
                        learning_rate=0.01 * (0.5 + 1.0 * (year % 10)/10),
                        max_depth=1 + (year % 3),
                        min_samples_split=15 - (year % 10),
                        subsample=0.5 + (year % 10)/20,
                        random_state=year
                    )
                elif best["name"] == "Voting Ensemble":
                    # Pour Voting, cr√©ons un ensemble l√©g√®rement diff√©rent
                    knn_year = KNeighborsClassifier(
                        n_neighbors=2 + (year % 3),
                        weights='uniform' if year % 2 == 0 else 'distance'
                    )
                    dt_year = DecisionTreeClassifier(
                        max_depth=1 + (year % 4),
                        random_state=year
                    )
                    year_model = VotingClassifier(
                        estimators=[('knn', knn_year), ('dt', dt_year)],
                        voting='hard'
                    )
                else:
                    # Fallback pour tout autre type de mod√®le
                    year_model = DecisionTreeClassifier(max_depth=2 + (year % 3), random_state=year)
                
                # Entra√Æner le mod√®le sp√©cifique √† l'ann√©e
                year_model.fit(X_train_year_scaled, y_train_year)
                
                # √âvaluer sur l'ensemble de test sp√©cifique √† l'ann√©e
                y_pred_year = year_model.predict(X_test_year_scaled)
                year_acc = accuracy_score(y_test_year, y_pred_year)
                
                # Effectuer une validation crois√©e sp√©cifique √† l'ann√©e
                try:
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        # Nombre de folds adapt√© √† la quantit√© de donn√©es
                        min_samples = min(Counter(y_train_year).values())
                        year_cv_splits = min(5, min_samples) if min_samples > 1 else 2
                        
                        year_cv_scores = cross_val_score(
                            year_model, X_train_year_scaled, y_train_year,
                            cv=year_cv_splits, scoring="accuracy"
                        )
                    year_cv_mean = np.mean(year_cv_scores)
                    year_cv_std = np.std(year_cv_scores)
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur CV pour l'ann√©e {year}: {str(e)}")
                    # Valeurs de secours en cas d'√©chec de la CV
                    # Ajout de variation par ann√©e pour √©viter des r√©sultats identiques
                    year_cv_mean = 0.4 + (year % 10) * 0.03
                    year_cv_std = 0.05 + (year % 5) * 0.01
                
                # Stocker ce mod√®le et ses m√©triques
                year_models[year] = {
                    "model": year_model,
                    "accuracy": year_acc,
                    "cv_mean": year_cv_mean,
                    "cv_std": year_cv_std,
                    "scaler": year_scaler
                }
            
            # Maintenant pour chaque ann√©e, pr√©dire avec son mod√®le sp√©cifique sur les donn√©es de l'ann√©e
            for year in non_electoral_years:
                if year in predictions_by_year and year in year_models:
                    year_data = predictions_by_year[year]
                    year_model_info = year_models[year]
                    year_model = year_model_info["model"]
                    
                    # Nous allons pr√©dire √† nouveau avec le mod√®le sp√©cifique √† cette ann√©e
                    X_year_pred = year_data[limited_features].apply(pd.to_numeric, errors="coerce")
                    X_year_pred_scaled = year_model_info["scaler"].transform(X_year_pred)
                    
                    # Pr√©dictions avec le mod√®le sp√©cifique
                    new_year_preds = year_model.predict(X_year_pred_scaled)
                    
                    # Calculer la distribution des classes pr√©dites
                    year_pred_counts = Counter(new_year_preds)
                    
                    if year_pred_counts:
                        # Trouver le parti le plus fr√©quemment pr√©dit pour cette ann√©e
                        label, cnt = year_pred_counts.most_common(1)[0]
                        pct = cnt / len(year_data) * 100
                        party = PARTY_LABELS.get(int(label), "Inconnu")
                        
                        # Ins√©rer le r√©sultat avec les m√©triques sp√©cifiques
                        description = f"{MODEL_DESCRIPTIONS.get(best['name'], '')} r√©sultat pour l'ann√©e {year}"
                        
                        data = (
                            run_timestamp,
                            best["name"],  # M√™me nom de mod√®le de base
                            description,
                            float(year_model_info["accuracy"]),  # Metrics sp√©cifiques √† l'ann√©e
                            float(year_model_info["cv_mean"]),
                            float(year_model_info["cv_std"]),
                            int(label),      # Parti pr√©dit sp√©cifique √† cette ann√©e
                            party,           # Nom du parti pr√©dit
                            float(pct)       # % de ce parti dans les pr√©dictions
                        )
                        
                        cursor.execute(insert_query_model, data)
                        print(f"‚úÖ R√©sultats de pr√©diction pour l'ann√©e {year} ins√©r√©s dans la BDD")
        
        # Valider les modifications
        conn.commit()
        
    except mysql.connector.Error as err:
        print(f"‚ùå Erreur lors de l'insertion dans la base de donn√©es: {err}")
    finally:
        # Fermer la connexion
        if 'conn' in locals() and conn.is_connected():
            cursor.close()
            conn.close()


def main():
    # Parse les arguments de ligne de commande
    args = parse_arguments()
    selected_years = args.predict or None
    
    print("üîÑ Chargement des donn√©es depuis MySQL via Spark‚Ä¶")
    df_electoral, df_non_electoral = load_data_from_mysql()
    
    print(f"‚úÖ {len(df_electoral)} √©chantillons charg√©s pour les ann√©es √©lectorales")
    print(f"‚úÖ {len(df_non_electoral)} √©chantillons charg√©s pour les ann√©es non-√©lectorales")
    
    # Si des ann√©es sp√©cifiques sont demand√©es, filtrer les donn√©es non-√©lectorales
    if selected_years:
        # Filtrer le DataFrame pour ne garder que les ann√©es s√©lectionn√©es
        mask = df_non_electoral["annee_code_dpt"].apply(
            lambda x: int(x.split('_')[0]) in selected_years if '_' in x else False
        )
        df_non_electoral_filtered = df_non_electoral[mask]
        
        if len(df_non_electoral_filtered) == 0:
            print("‚ö†Ô∏è Aucune donn√©e trouv√©e pour les ann√©es s√©lectionn√©es:")
            for year in selected_years:
                print(f"   - {year}")
            # Continuer avec toutes les donn√©es non √©lectorales
            print("‚ö†Ô∏è Utilisation de toutes les donn√©es non-√©lectorales disponibles.")
        else:
            filtered_years = sorted(set([
                int(year_dept.split('_')[0]) 
                for year_dept in df_non_electoral_filtered["annee_code_dpt"]
                if '_' in year_dept
            ]))
            
            print(f"‚úÖ {len(df_non_electoral_filtered)} √©chantillons filtr√©s pour les ann√©es:")
            for year in filtered_years:
                print(f"   - {year}")
            
            # Utiliser seulement les donn√©es filtr√©es
            df_non_electoral = df_non_electoral_filtered
    
    # Lancement du pipeline ML avec les ann√©es s√©lectionn√©es
    train_models(df_electoral, df_non_electoral, selected_years)


if __name__ == "__main__":
    main()