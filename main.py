# main.py

import logging
import os

from etl.extract import DataExtractor
from etl.transform import DataTransformer
from etl.loader import DataLoader

# Import de la librairie dotenv pour charger les variables d'environnement
from dotenv import load_dotenv

# Chargement des variables d'environnement
load_dotenv()


# Configuration du logger
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def extract_data():
    """
    Extrait les donn√©es √† partir de diff√©rentes sources.
    
    Returns:
        dict: Dictionnaire contenant tous les DataFrames extraits
    """
    logger.info("üöÄ Extraction des donn√©es")

    # Initialisation de l'extracteur
    extractor = DataExtractor()

    # D√©finition des chemins
    logger.info("üìÅ   Configuration des chemins de fichiers...")
    input_file_path = (
        "./data/origine/environnemental/parc-regional-annuel-prod-eolien-solaire.csv"
    )

    pib_files = [
        "./data/origine/socio-economie/PIB Guadeloupe.csv",
        "./data/origine/socio-economie/PIB Martinique.csv",
        "./data/origine/socio-economie/PIB Guyane.csv",
        "./data/origine/socio-economie/PIB La R√©union.csv",
        "./data/origine/socio-economie/PIB Mayotte.csv",
    ]

    region_codes = {
        "./data/origine/socio-economie/PIB Guadeloupe.csv": "01",
        "./data/origine/socio-economie/PIB Martinique.csv": "02",
        "./data/origine/socio-economie/PIB Guyane.csv": "03",
        "./data/origine/socio-economie/PIB La R√©union.csv": "04",
        "./data/origine/socio-economie/PIB Mayotte.csv": "06",
    }

    pib_xlsx_file = "./data/origine/socio-economie/PIB 1990 - 2021.xlsx"
    pib_2022_file = "./data/origine/socio-economie/PIB par R√©gion en 2022.csv"
    inflation_xlsx_file = "./data/origine/socio-economie/Essentiel_Inflation_donnees.xlsx"
    technologie_xlsx_file = "./data/origine/technologie/Effort-recherche_tableaux_2024.xlsx"
    election_files_pattern = (
        "./data/origine/politique/taux-votes/1965_2012/cdsp_presi*t2_circ.csv"
    )
    election_2017_file = (
        "./data/origine/politique/taux-votes/2017/Presidentielle_2017_Resultats_Tour_2_c.xls"
    )
    election_2022_file = "./data/origine/politique/taux-votes/2022/resultats-par-niveau-subcom-t2-france-entiere.xlsx"
    orientation_politique_file = (
        "./data/origine/politique/partie_politiques/partie_politiques_1965_2022.csv"
    )
    education_file = "./data/origine/education/fr-en-etablissements-fermes.csv"
    life_expectancy_file = "./data/origine/sante/valeurs_annuelles.csv"
    departments_file_path = "./data/origine/politique/departements-france.csv"
    security_excel_file = "./data/origine/securite/tableaux-4001-ts.xlsx"
    demo_file_xls = "./data/origine/demographie/estim-pop-dep-sexe-gca-1975-2023.xls"
    demo_file_xlsx = demo_file_xls.replace(".xls", ".xlsx")
    demo_csv = "./data/origine/demographie/demographie_fusion.csv"

    # Donn√©es environnementales
    df_env = extractor.extract_environmental_data(input_file_path)
    if df_env is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es environnementales.")
        return None
    extracted_data = {'env': df_env}
    # PIB des r√©gions d'outre-mer
    df_pib = extractor.extract_pib_outre_mer(pib_files)
    if df_pib is None:
        logger.error("‚ùå Extraction PIB √©chou√©e.")
        return None
    extracted_data['pib'] = df_pib

    # PIB r√©gionaux (nouveaux fichiers)
    df_pib_xlsx = extractor.extract_pib_excel(pib_xlsx_file)
    df_pib_2022 = extractor.extract_pib_2022(pib_2022_file)
    if df_pib_xlsx is None or df_pib_2022 is None:
        logger.error("‚ùå Extraction PIB Excel √©chou√©e.")
        return None
    extracted_data['pib_xlsx'] = df_pib_xlsx
    extracted_data['pib_2022'] = df_pib_2022

    # Donn√©es d'inflation
    df_inflation = extractor.extract_inflation_data(inflation_xlsx_file)
    if df_inflation is None:
        logger.error("‚ùå Extraction Inflation √©chou√©e.")
        return None
    extracted_data['inflation'] = df_inflation

    # Donn√©es de technologie
    df_technologie = extractor.extract_technologie_data(technologie_xlsx_file)
    if df_technologie is None:
        logger.error("‚ùå Extraction des donn√©es de technologie √©chou√©e.")
        return None
    extracted_data['technologie'] = df_technologie

    # Donn√©es √©lectorales
    df_election_1965_2012 = extractor.extract_election_data_1965_2012(election_files_pattern)
    df_election_2017 = extractor.extract_election_data_2017(election_2017_file)
    df_election_2022 = extractor.extract_election_data_2022(election_2022_file)
    extracted_data['election_1965_2012'] = df_election_1965_2012
    extracted_data['election_2017'] = df_election_2017
    extracted_data['election_2022'] = df_election_2022

    # Donn√©es de d√©mographie
    df_demographie = extractor.extract_demography_data(demo_file_xls, demo_file_xlsx, demo_csv)
    if df_demographie is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es de d√©mographie.")
        return None
    extracted_data['demographie'] = df_demographie

    # Donn√©es d'√©ducation
    df_education = extractor.extract_education_data(education_file)
    if df_education is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es d'√©ducation")
        return None
    extracted_data['education'] = df_education

    # Donn√©es de s√©curit√©
    df_security = extractor.extract_security_data(security_excel_file)
    if df_security is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es de s√©curit√©")
        return None
    extracted_data['security'] = df_security

    # Donn√©es de sant√©
    df_life_expectancy_raw = extractor.extract_life_expectancy_data(life_expectancy_file)
    if df_life_expectancy_raw is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es d'esp√©rance de vie.")
        return None
    extracted_data['life_expectancy'] = df_life_expectancy_raw

    # Donn√©es des d√©partements
    df_departments = extractor.extract_departments_data(departments_file_path)
    if df_departments is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es des d√©partements.")
        return None
    extracted_data['departments'] = df_departments

    # Donn√©es d'orientation politique
    df_orientation_politique = extractor.extract_orientation_politique(orientation_politique_file)
    if df_orientation_politique is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es d'orientation politique.")
        return None
    extracted_data['orientation_politique'] = df_orientation_politique

    # Stockage des m√©tadonn√©es n√©cessaires √† la transformation
    extracted_data |= {
        'region_codes': region_codes,
        'file_paths': {
            'input_file_path': input_file_path,
            'education_file': education_file,
            'demo_csv': demo_csv,
        },
    }

    logger.info("‚úÖ Extraction de toutes les donn√©es r√©ussie")
    return extracted_data, extractor.spark


def transform_data(data, spark):
    """
    Transforme les donn√©es extraites.
    
    Args:
        data (dict): Dictionnaire contenant tous les DataFrames extraits
        spark: Session Spark active
        
    Returns:
        dict: Dictionnaire des DataFrames transform√©s
    """
    logger.info("üöÄ Transformation des donn√©es")
    transformer = DataTransformer()
    # Transformation des donn√©es environnementales
    df_transformed = transformer.transform_environmental_data(data['env'])
    if df_transformed is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es environnementales.")
        return None
    transformed_data = {'env': df_transformed}
    # Transformation des donn√©es PIB
    df_pib_transformed = transformer.transform_pib_outre_mer(data['pib'], data['region_codes'])
    df_pib_transformed_completed = transformer.fill_missing_pib_mayotte(df_pib_transformed)
    if df_pib_transformed_completed is None:
        logger.error("‚ùå Remplissage PIB Mayotte √©chou√©.")
        return None

    # Combinaison finale de toutes les donn√©es PIB
    df_pib_total = transformer.combine_all_pib_data(
        df_pib_transformed_completed, data['pib_xlsx'], data['pib_2022']
    )
    if df_pib_total is None:
        logger.error("‚ùå Combinaison PIB √©chou√©e.")
        return None

    # Transformation des donn√©es d'inflation et combinaison avec PIB
    df_inflation_transformed = transformer.transform_inflation_data(data['inflation'])
    if df_inflation_transformed is None:
        logger.error("‚ùå Transformation Inflation √©chou√©e.")
        return None

    df_pib_inflation = transformer.combine_pib_and_inflation(
        df_pib_total, df_inflation_transformed
    )
    if df_pib_inflation is None:
        logger.error("‚ùå Fusion PIB + Inflation √©chou√©e.")
        return None
    transformed_data['pib_inflation'] = df_pib_inflation

    # Transformation des donn√©es de technologie
    df_technologie_transformed = transformer.transform_technologie_data(data['technologie'])
    if df_technologie_transformed is None:
        logger.error("‚ùå Transformation des donn√©es de technologie √©chou√©e.")
        return None
    transformed_data['technologie'] = df_technologie_transformed

    # Transformation des donn√©es √©lectorales
    df_election_1965_2012_transformed = transformer.transform_election_data_1965_2012(data['election_1965_2012'])
    if df_election_1965_2012_transformed is None:
        logger.error("‚ùå Transformation des donn√©es √©lectorales 1965-2012 √©chou√©e.")
        return None

    df_election_2017_transformed = transformer.transform_election_data_2017(data['election_2017'])
    if df_election_2017_transformed is None:
        logger.error("‚ùå Transformation des donn√©es √©lectorales 2017 √©chou√©e.")
        return None

    df_election_2022_transformed = transformer.transform_election_data_2022(data['election_2022'])
    if df_election_2022_transformed is None:
        logger.error("‚ùå Transformation des donn√©es √©lectorales 2022 √©chou√©e.")
        return None

    # Combinaison de toutes les ann√©es √©lectorales
    df_election_final = transformer.combine_all_years(
        df_election_1965_2012_transformed,
        df_election_2017_transformed,
        df_election_2022_transformed
    )

    # Combinaison avec orientation politique
    df_election_final = transformer.combine_election_and_orientation_politique(
        df_election_final, data['orientation_politique']
    )
    if df_election_final is None:
        logger.error("‚ùå Combinaison des donn√©es √©lectorales √©chou√©e.")
        return None
    transformed_data['election'] = df_election_final

    # Transformation des donn√©es d√©mographiques
    df_demographie_transformed = transformer.transform_demography_data(data['demographie'])
    if df_demographie_transformed is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es de d√©mographie.")
        return None
    transformed_data['demographie'] = df_demographie_transformed

    # Transformation des donn√©es d'√©ducation
    df_edu_clean = transformer.transform_education_data(data['education'])
    df_edu_grouped = transformer.calculate_closed_by_year_and_dept_education(df_edu_clean)
    if df_edu_grouped is None:
        logger.error("‚ùå √âchec du calcul des statistiques d'√©ducation")
        return None
    transformed_data['education'] = df_edu_grouped

    # Transformation des donn√©es de s√©curit√©
    df_security_transformed = transformer.transform_security_data(data['security'])
    if df_security_transformed is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es de s√©curit√©")
        return None
    transformed_data['security'] = df_security_transformed

    # Transformation des donn√©es de sant√©
    df_life_final = transformer.transform_life_expectancy_data(
        data['life_expectancy'], data['departments']
    )
    if df_life_final is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es d'esp√©rance de vie.")
        return None
    df_life_final = transformer.fill_missing_mayotte_life_expectancy(df_life_final)
    transformed_data['life_expectancy'] = df_life_final

    logger.info("‚úÖ Transformation de toutes les donn√©es r√©ussie")
    return transformed_data


def load_data(data, spark, file_paths):
    """
    Charge les donn√©es transform√©es dans des fichiers CSV.
    
    Args:
        data (dict): Dictionnaire des DataFrames transform√©s
        spark: Session Spark active
        file_paths (dict): Chemins des fichiers
    """
    logger.info("üöÄ Chargement des donn√©es")
    loader = DataLoader(spark)

    # Sauvegarde des donn√©es dans des fichiers CSV
    loader.save_to_csv(data['env'], file_paths['input_file_path'])
    loader.save_to_csv(data['education'], file_paths['education_file'])
    loader.save_to_csv(data['pib_inflation'], "pib_inflation_final.csv")
    loader.save_to_csv(data['technologie'], "technologie_pib_france_1990_2023.csv")
    loader.save_to_csv(data['election'], "vote_presidentiel_par_dept_1965_2022.csv")
    loader.save_to_csv(data['life_expectancy'], "esperance_de_vie_par_departement_2000_2022.csv")
    loader.save_to_csv(data['security'], "delits_par_departement_1996_2022.csv")
    loader.save_to_csv(data['demographie'], file_paths['demo_csv'])

    # D√©finition des chemins vers les fichiers consolid√©s
    election_csv = "data/processed_data/vote_presidentiel_par_dept_1965_2022_processed.csv"
    security_csv = "data/processed_data/delits_par_departement_1996_2022_processed.csv"
    socio_csv = "data/processed_data/pib_inflation_final_processed.csv"
    sante_csv = "data/processed_data/esperance_de_vie_par_departement_2000_2022_processed.csv"
    env_csv = "data/processed_data/parc-regional-annuel-prod-eolien-solaire_processed.csv"
    edu_csv = "data/processed_data/fr-en-etablissements-fermes_processed.csv"
    demo_csv = "data/processed_data/demographie_fusion_processed.csv"
    tech_csv = "data/processed_data/technologie_pib_france_1990_2023_processed.csv"

    # G√©n√©ration du fichier consolid√©
    loader.generate_consolidated_csv_from_files(
        election_csv=election_csv,
        security_csv=security_csv,
        socio_csv=socio_csv,
        sante_csv=sante_csv,
        env_csv=env_csv,
        edu_csv=edu_csv,
        demo_csv=demo_csv,
        tech_csv=tech_csv,
        output_filename="consolidated_data.csv"
    )
    
    logger.info("‚úÖ Chargement des donn√©es termin√©")
    return


def load_data_to_mysql(transformed_data, spark, db_config=None):
    """
    Charge les donn√©es transform√©es dans MySQL.
    
    Args:
        transformed_data (dict): Dictionnaire des DataFrames transform√©s
        spark: Session Spark active
        db_config: Configuration de la base de donn√©es MySQL
    """
    logger.info("üöÄ Chargement des donn√©es dans MySQL")
    
    
    if db_config is None:
        db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'user': os.getenv('DB_USER', 'root'),
            'password': os.getenv('DB_PASSWORD', ''),
            'database': os.getenv('DB_NAME', 'elections_presidentielles'),
            'port': int(os.getenv('DB_PORT', '3306'))
        }
    
    loader = DataLoader(spark, "data/processed_data", db_config)
    
    # Configuration de la base de donn√©es
    loader.setup_database()
    
    # D√©finition des mappages de colonnes pour chaque dimension
    mappings = {
        'environnement': {
            'Code_INSEE_R√©gion': 'code_insee_region',
            'Ann√©e': 'annee',
            'Parc_install√©_√©olien_MW': 'parc_eolien_mw',
            'Parc_install√©_solaire_MW': 'parc_solaire_mw'
        },
        'socio_economie': {
            'Ann√©e': 'annee',
            'PIB_en_euros_par_habitant': 'pib_euros_par_habitant',
            'Code_INSEE_R√©gion': 'code_insee_region',
            '√âvolution_des_prix_√†_la_consommation': 'evolution_prix_conso',
            'PIB_par_inflation': 'pib_par_inflation'
        },
        'technologie': {
            'annee': 'annee',
            'dird_pib_france_pourcentages': 'depenses_rd_pib'
        },
        'politique': {
            'annee': 'annee',
            'code_dept': 'code_dept',
            'id_parti': 'etiquette_parti',
            'candidat': 'candidat',
            'total_voix': 'total_voix',
            'orientation_politique': 'orientation_politique'
        },
        'sante': {
            'CODE_DEP': 'code_dept',
            'Ann√©e': 'annee',
            'Esp√©rance_Vie': 'esperance_vie'
        },
        'securite': {
            'Ann√©e': 'annee',
            'D√©partement': 'code_dept',
            'D√©lits_total': 'delits_total'
        },
        'demographie': {
            'Ann√©e': 'annee',
            'Code_D√©partement': 'code_departement',
            'Nom_D√©partement': 'nom_departement',
            'E_Total': 'population_totale',
            'H_Total': 'population_hommes',
            'F_Total': 'population_femmes',
            'E_0_19_ans': 'pop_0_19',
            'E_20_39_ans': 'pop_20_39',
            'E_40_59_ans': 'pop_40_59',
            'E_60_74_ans': 'pop_60_74',
            'E_75_plus': 'pop_75_plus'
        },
        'education': {
            'annee_fermeture': 'annee_fermeture',
            'code_departement': 'code_departement',
            'libelle_departement': 'libelle_departement',
            'nombre_total_etablissements': 'nombre_total_etablissements',
            'nb_public': 'nb_public',
            'nb_prive': 'nb_prive',
            'pct_public': 'pct_public',
            'pct_prive': 'pct_prive'
        }
    }
    
    # Insertion directe des donn√©es avec les mappages appropri√©s
    loader.insert_data_to_mysql("dim_environnement", transformed_data['env'], mappings['environnement'])
    loader.insert_data_to_mysql("dim_socio_economie", transformed_data['pib_inflation'], mappings['socio_economie'])
    loader.insert_data_to_mysql("dim_technologie", transformed_data['technologie'], mappings['technologie'])
    loader.insert_data_to_mysql("dim_politique", transformed_data['election'], mappings['politique'])
    loader.insert_data_to_mysql("dim_sante", transformed_data['life_expectancy'], mappings['sante'])
    loader.insert_data_to_mysql("dim_securite", transformed_data['security'], mappings['securite'])
    loader.insert_data_to_mysql("dim_demographie", transformed_data['demographie'], mappings['demographie'])
    loader.insert_data_to_mysql("dim_education", transformed_data['education'], mappings['education'])

    # Variables utilis√©es pour la cr√©ation de la table de faits
    TARGET_YEARS = list(range(2000, 2023))
    desired_depts = [f"{i:02d}" for i in range(1, 96) if i != 20]
    
    # Cr√©er la table de faits uniquement √† partir des dimensions d√©j√† ins√©r√©es
    success = loader.create_fact_table(TARGET_YEARS, desired_depts)
    
    if success:
        logger.info("‚úÖ Donn√©es charg√©es dans MySQL avec succ√®s")
    else:
        logger.error("‚ùå √âchec du chargement des donn√©es dans MySQL")
    
    return success

def main():
    """
    Point d'entr√©e principal de l'ETL utilisant des fonctions d√©compos√©es :
    - Extraction des donn√©es via extract_data()
    - Transformation des donn√©es via transform_data()
    - Chargement des donn√©es via load_data() (CSV)
    - Chargement des donn√©es via load_data_to_mysql() (MySQL)
    """
    logger.info("üöÄ D√©marrage du processus ETL")

    try:
        # Extraction des donn√©es
        extracted_data, spark = extract_data()
        if extracted_data is None:
            logger.error("‚ùå √âchec de l'√©tape d'extraction. Arr√™t du programme.")
            return
            
        # Transformation des donn√©es
        transformed_data = transform_data(extracted_data, spark)
        if transformed_data is None:
            logger.error("‚ùå √âchec de l'√©tape de transformation. Arr√™t du programme.")
            return
            
        # Chargement des donn√©es (CSV)
        load_data(transformed_data, spark, extracted_data['file_paths'])
        
        # Chargement des donn√©es dans MySQL
        # Sp√©cifiez vos param√®tres de connexion MySQL ici
        db_config = {
            'host': os.getenv('DB_HOST'),
            'user': os.getenv('DB_USER'),
            'password': os.getenv('DB_PASSWORD'),
            'database': os.getenv('DB_NAME'),
            'port': int(os.getenv('DB_PORT'))
        }
        load_data_to_mysql(transformed_data, spark, db_config)
        
        # Arr√™t de la session Spark
        from pyspark.sql import SparkSession
        spark_session = SparkSession.builder.getOrCreate()
        spark_session.stop()
        
        logger.info("‚úÖ Processus ETL termin√© avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du processus ETL : {str(e)}")
        raise


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du processus ETL : {str(e)}")
        raise