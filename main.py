# main.py

import logging
import os
from etl.extract import DataExtractor
from etl.transform import DataTransformer
from etl.loader import DataLoader
from dotenv import load_dotenv

# Chargement des variables d'environnement
load_dotenv()

# Configuration du logger
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def extract_data():
    """
    Extrait les donn√©es √† partir de diff√©rentes sources.
    
    Returns:
        dict: Dictionnaire contenant tous les DataFrames extraits
    """
    logger.info("üöÄ   Extraction des donn√©es")

    # Initialisation de l'extracteur
    extractor = DataExtractor()

    # D√©finition des chemins
    logger.info("üìÅ   Configuration des chemins de fichiers...")
    input_file_path = (
        "./data/environnemental/parc-regional-annuel-prod-eolien-solaire.csv"
    )

    pib_files = [
        "./data/socio-economie/PIB Guadeloupe.csv",
        "./data/socio-economie/PIB Martinique.csv",
        "./data/socio-economie/PIB Guyane.csv",
        "./data/socio-economie/PIB La R√©union.csv",
        "./data/socio-economie/PIB Mayotte.csv",
    ]

    region_codes = {
        "./data/socio-economie/PIB Guadeloupe.csv": "01",
        "./data/socio-economie/PIB Martinique.csv": "02",
        "./data/socio-economie/PIB Guyane.csv": "03",
        "./data/socio-economie/PIB La R√©union.csv": "04",
        "./data/socio-economie/PIB Mayotte.csv": "06",
    }

    pib_xlsx_file = "./data/socio-economie/PIB 1990 - 2021.xlsx"
    pib_2022_file = "./data/socio-economie/PIB par R√©gion en 2022.csv"
    inflation_xlsx_file = "./data/socio-economie/Essentiel_Inflation_donnees.xlsx"
    technologie_xlsx_file = "./data/technologie/Effort-recherche_tableaux_2024.xlsx"
    election_files_pattern = (
        "./data/politique/taux-votes/1965_2012/cdsp_presi*t2_circ.csv"
    )
    election_2017_file = (
        "./data/politique/taux-votes/2017/Presidentielle_2017_Resultats_Tour_2_c.xls"
    )
    election_2022_file = "./data/politique/taux-votes/2022/resultats-par-niveau-subcom-t2-france-entiere.xlsx"
    orientation_politique_file = (
        "./data/politique/partie_politiques/partie_politiques_1965_2022.csv"
    )
    education_file = "./data/education/fr-en-etablissements-fermes.csv"
    life_expectancy_file = "./data/sante/valeurs_annuelles.csv"
    departments_file_path = "./data/politique/departements-france.csv"
    security_excel_file = "./data/securite/tableaux-4001-ts.xlsx"
    demo_file_xls = "./data/demographie/estim-pop-dep-sexe-gca-1975-2023.xls"
    demo_file_xlsx = demo_file_xls.replace(".xls", ".xlsx")
    demo_csv = "./data/demographie/demographie_fusion.csv"

    # Donn√©es environnementales
    df_env = extractor.extract_environmental_data(input_file_path)
    if df_env is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es environnementales.")
        return None
    extracted_data = {'env': df_env}
    # PIB des r√©gions d'outre-mer
    df_pib = extractor.extract_pib_outre_mer(pib_files)
    if df_pib is None:
        logger.error("‚ùå Extraction PIB √©chou√©e.")
        return None
    extracted_data['pib'] = df_pib

    # PIB r√©gionaux (nouveaux fichiers)
    df_pib_xlsx = extractor.extract_pib_excel(pib_xlsx_file)
    df_pib_2022 = extractor.extract_pib_2022(pib_2022_file)
    if df_pib_xlsx is None or df_pib_2022 is None:
        logger.error("‚ùå Extraction PIB Excel √©chou√©e.")
        return None
    extracted_data['pib_xlsx'] = df_pib_xlsx
    extracted_data['pib_2022'] = df_pib_2022

    # Donn√©es d'inflation
    df_inflation = extractor.extract_inflation_data(inflation_xlsx_file)
    if df_inflation is None:
        logger.error("‚ùå Extraction Inflation √©chou√©e.")
        return None
    extracted_data['inflation'] = df_inflation

    # Donn√©es de technologie
    df_technologie = extractor.extract_technologie_data(technologie_xlsx_file)
    if df_technologie is None:
        logger.error("‚ùå Extraction des donn√©es de technologie √©chou√©e.")
        return None
    extracted_data['technologie'] = df_technologie

    # Donn√©es √©lectorales
    df_election_1965_2012 = extractor.extract_election_data_1965_2012(election_files_pattern)
    df_election_2017 = extractor.extract_election_data_2017(election_2017_file)
    df_election_2022 = extractor.extract_election_data_2022(election_2022_file)
    extracted_data['election_1965_2012'] = df_election_1965_2012
    extracted_data['election_2017'] = df_election_2017
    extracted_data['election_2022'] = df_election_2022

    # Donn√©es de d√©mographie
    df_demographie = extractor.extract_demography_data(demo_file_xls, demo_file_xlsx, demo_csv)
    if df_demographie is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es de d√©mographie.")
        return None
    extracted_data['demographie'] = df_demographie

    # Donn√©es d'√©ducation
    df_education = extractor.extract_education_data(education_file)
    if df_education is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es d'√©ducation")
        return None
    extracted_data['education'] = df_education

    # Donn√©es de s√©curit√©
    df_security = extractor.extract_security_data(security_excel_file)
    if df_security is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es de s√©curit√©")
        return None
    extracted_data['security'] = df_security

    # Donn√©es de sant√©
    df_life_expectancy_raw = extractor.extract_life_expectancy_data(life_expectancy_file)
    if df_life_expectancy_raw is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es d'esp√©rance de vie.")
        return None
    extracted_data['life_expectancy'] = df_life_expectancy_raw

    # Donn√©es des d√©partements
    df_departments = extractor.extract_departments_data(departments_file_path)
    if df_departments is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es des d√©partements.")
        return None
    extracted_data['departments'] = df_departments

    # Donn√©es d'orientation politique
    df_orientation_politique = extractor.extract_orientation_politique(orientation_politique_file)
    if df_orientation_politique is None:
        logger.error("‚ùå √âchec de l'extraction des donn√©es d'orientation politique.")
        return None
    extracted_data['orientation_politique'] = df_orientation_politique

    # Stockage des m√©tadonn√©es n√©cessaires √† la transformation
    extracted_data |= {
        'region_codes': region_codes,
        'file_paths': {
            'input_file_path': input_file_path,
            'education_file': education_file,
            'demo_csv': demo_csv,
        },
    }

    logger.info("‚úÖ Extraction de toutes les donn√©es r√©ussie")
    return extracted_data, extractor.spark


def transform_data(data, spark):
    """
    Transforme les donn√©es extraites.
    
    Args:
        data (dict): Dictionnaire contenant tous les DataFrames extraits
        spark: Session Spark active
        
    Returns:
        dict: Dictionnaire des DataFrames transform√©s et pr√©par√©s pour le chargement
    """
    logger.info("üöÄ Transformation des donn√©es")
    transformer = DataTransformer()
    
    # Dictionnaire pour stocker les donn√©es transform√©es
    transformed_data = {}
    
    # Dictionnaire pour stocker les donn√©es pr√©par√©es pour le sch√©ma en √©toile
    star_schema_data = {}
    
    # Transformation des donn√©es environnementales
    df_env_transformed = transformer.transform_environmental_data(data['env'])
    if df_env_transformed is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es environnementales.")
        return None, None
    transformed_data['env'] = df_env_transformed
    
    # Pr√©paration des donn√©es environnementales pour le sch√©ma en √©toile
    dim_environnement = transformer.prepare_dim_environnement(df_env_transformed)
    star_schema_data['dim_environnement'] = dim_environnement
    
    # Transformation des donn√©es PIB
    df_pib_transformed = transformer.transform_pib_outre_mer(data['pib'], data['region_codes'])
    df_pib_transformed_completed = transformer.fill_missing_pib_mayotte(df_pib_transformed)
    if df_pib_transformed_completed is None:
        logger.error("‚ùå Remplissage PIB Mayotte √©chou√©.")
        return None, None

    # Combinaison finale de toutes les donn√©es PIB
    df_pib_total = transformer.combine_all_pib_data(
        df_pib_transformed_completed, data['pib_xlsx'], data['pib_2022']
    )
    if df_pib_total is None:
        logger.error("‚ùå Combinaison PIB √©chou√©e.")
        return None, None

    # Transformation des donn√©es d'inflation et combinaison avec PIB
    df_inflation_transformed = transformer.transform_inflation_data(data['inflation'])
    if df_inflation_transformed is None:
        logger.error("‚ùå Transformation Inflation √©chou√©e.")
        return None, None

    df_pib_inflation = transformer.combine_pib_and_inflation(
        df_pib_total, df_inflation_transformed
    )
    if df_pib_inflation is None:
        logger.error("‚ùå Fusion PIB + Inflation √©chou√©e.")
        return None, None
    transformed_data['pib_inflation'] = df_pib_inflation
    
    # Pr√©paration des donn√©es socio-√©conomiques pour le sch√©ma en √©toile
    dim_socio_economie = transformer.prepare_dim_socio_economie(df_pib_inflation)
    star_schema_data['dim_socio_economie'] = dim_socio_economie

    # Transformation des donn√©es de technologie
    df_technologie_transformed = transformer.transform_technologie_data(data['technologie'])
    if df_technologie_transformed is None:
        logger.error("‚ùå Transformation des donn√©es de technologie √©chou√©e.")
        return None, None
    transformed_data['technologie'] = df_technologie_transformed
    
    # Pr√©paration des donn√©es de technologie pour le sch√©ma en √©toile
    dim_technologie = transformer.prepare_dim_technologie(df_technologie_transformed)
    star_schema_data['dim_technologie'] = dim_technologie

    # Transformation des donn√©es √©lectorales
    df_election_1965_2012_transformed = transformer.transform_election_data_1965_2012(data['election_1965_2012'])
    if df_election_1965_2012_transformed is None:
        logger.error("‚ùå Transformation des donn√©es √©lectorales 1965-2012 √©chou√©e.")
        return None, None

    df_election_2017_transformed = transformer.transform_election_data_2017(data['election_2017'])
    if df_election_2017_transformed is None:
        logger.error("‚ùå Transformation des donn√©es √©lectorales 2017 √©chou√©e.")
        return None, None

    df_election_2022_transformed = transformer.transform_election_data_2022(data['election_2022'])
    if df_election_2022_transformed is None:
        logger.error("‚ùå Transformation des donn√©es √©lectorales 2022 √©chou√©e.")
        return None, None

    # Combinaison de toutes les ann√©es √©lectorales
    df_election_final = transformer.combine_all_years(
        df_election_1965_2012_transformed,
        df_election_2017_transformed,
        df_election_2022_transformed
    )

    # Combinaison avec orientation politique
    df_election_final = transformer.combine_election_and_orientation_politique(
        df_election_final, data['orientation_politique']
    )
    if df_election_final is None:
        logger.error("‚ùå Combinaison des donn√©es √©lectorales √©chou√©e.")
        return None, None
    transformed_data['election'] = df_election_final
    
    # Pr√©paration des donn√©es politiques pour le sch√©ma en √©toile
    dim_politique = transformer.prepare_dim_politique(df_election_final)
    star_schema_data['dim_politique'] = dim_politique

    # Transformation des donn√©es d√©mographiques
    df_demographie_transformed = transformer.transform_demography_data(data['demographie'])
    if df_demographie_transformed is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es de d√©mographie.")
        return None, None
    transformed_data['demographie'] = df_demographie_transformed
    
    # Pr√©paration des donn√©es d√©mographiques pour le sch√©ma en √©toile
    dim_demographie = transformer.prepare_dim_demographie(df_demographie_transformed)
    star_schema_data['dim_demographie'] = dim_demographie

    # Transformation des donn√©es d'√©ducation
    df_edu_clean = transformer.transform_education_data(data['education'])
    df_edu_grouped = transformer.calculate_closed_by_year_and_dept_education(df_edu_clean)
    if df_edu_grouped is None:
        logger.error("‚ùå √âchec du calcul des statistiques d'√©ducation")
        return None, None
    transformed_data['education'] = df_edu_grouped
    
    # Pr√©paration des donn√©es d'√©ducation pour le sch√©ma en √©toile
    dim_education = transformer.prepare_dim_education(df_edu_grouped)
    star_schema_data['dim_education'] = dim_education

    # Transformation des donn√©es de s√©curit√©
    df_security_transformed = transformer.transform_security_data(data['security'])
    if df_security_transformed is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es de s√©curit√©")
        return None, None
    transformed_data['security'] = df_security_transformed
    
    # Pr√©paration des donn√©es de s√©curit√© pour le sch√©ma en √©toile
    dim_securite = transformer.prepare_dim_securite(df_security_transformed)
    star_schema_data['dim_securite'] = dim_securite

    # Transformation des donn√©es de sant√©
    df_life_final = transformer.transform_life_expectancy_data(
        data['life_expectancy'], data['departments']
    )
    if df_life_final is None:
        logger.error("‚ùå √âchec de la transformation des donn√©es d'esp√©rance de vie.")
        return None, None
    df_life_final = transformer.fill_missing_mayotte_life_expectancy(df_life_final)
    transformed_data['life_expectancy'] = df_life_final
    
    # Pr√©paration des donn√©es de sant√© pour le sch√©ma en √©toile
    dim_sante = transformer.prepare_dim_sante(df_life_final)
    star_schema_data['dim_sante'] = dim_sante
    
    # Cr√©ation de la table de faits
    fact_resultats_politique = transformer.prepare_fact_resultats_politique(
        dim_politique, 
        dim_securite, 
        dim_socio_economie, 
        dim_sante, 
        dim_environnement, 
        dim_education, 
        dim_demographie, 
        dim_technologie
    )
    star_schema_data['fact_resultats_politique'] = fact_resultats_politique

    logger.info("‚úÖ Transformation de toutes les donn√©es r√©ussie")
    return transformed_data, star_schema_data


def load_data(data, star_schema_data, spark, file_paths):
    """
    Charge les donn√©es transform√©es dans des fichiers CSV et dans la base de donn√©es MySQL.
    
    Args:
        data (dict): Dictionnaire des DataFrames transform√©s
        star_schema_data (dict): Dictionnaire des DataFrames pr√©par√©s pour le sch√©ma en √©toile
        spark: Session Spark active
        file_paths (dict): Chemins des fichiers
    """
    logger.info("üöÄ Chargement des donn√©es")
    
    # Param√®tres de connexion MySQL depuis les variables d'environnement
    jdbc_url = os.getenv("MYSQL_JDBC_URL", "jdbc:mysql://localhost:3306")
    user = os.getenv("MYSQL_USER", "root")
    password = os.getenv("MYSQL_PASSWORD", "")
    database = os.getenv("MYSQL_DATABASE", "elections_presidentielles")
    
    # Initialisation du DataLoader
    loader = DataLoader(
        spark=spark,
        jdbc_url=jdbc_url,
        user=user,
        password=password,
        database=database
    )

    # 1. Sauvegarde des donn√©es transform√©es dans des fichiers CSV
    logger.info("üîÑ Sauvegarde des donn√©es transform√©es en CSV...")
    loader.save_to_csv(data['env'], file_paths['input_file_path'])
    loader.save_to_csv(data['education'], file_paths['education_file'])
    loader.save_to_csv(data['pib_inflation'], "pib_inflation_final.csv")
    loader.save_to_csv(data['technologie'], "technologie_pib_france_1990_2023.csv")
    loader.save_to_csv(data['election'], "vote_presidentiel_par_dept_1965_2022.csv")
    loader.save_to_csv(data['life_expectancy'], "esperance_de_vie_par_departement_2000_2022.csv")
    loader.save_to_csv(data['security'], "delits_par_departement_1996_2022.csv")
    loader.save_to_csv(data['demographie'], file_paths['demo_csv'])

    try:
        # *** MODIFICATION 1: Supprimer d'abord la table de faits pour lib√©rer les contraintes FK ***
        loader.drop_fact_table()
        
        # 2. Chargement des donn√©es dans MySQL selon le sch√©ma en √©toile
        logger.info("üîÑ Chargement des donn√©es dans MySQL...")
        
        # Chargement des dimensions avec TRUNCATE au lieu de DROP+CREATE
        logger.info("üîÑ Chargement des dimensions...")
        loader.truncate_and_load_dim("dim_politique", star_schema_data['dim_politique'])
        loader.truncate_and_load_dim("dim_securite", star_schema_data['dim_securite'])
        loader.truncate_and_load_dim("dim_sante", star_schema_data['dim_sante'])
        loader.truncate_and_load_dim("dim_education", star_schema_data['dim_education'])
        loader.truncate_and_load_dim("dim_environnement", star_schema_data['dim_environnement'])
        loader.truncate_and_load_dim("dim_socio_economie", star_schema_data['dim_socio_economie'])
        loader.truncate_and_load_dim("dim_technologie", star_schema_data['dim_technologie'])
        loader.truncate_and_load_dim("dim_demographie", star_schema_data['dim_demographie'])
        
        # Chargement de la table de faits
        logger.info("üîÑ Chargement de la table de faits...")
        if star_schema_data['fact_resultats_politique'] is not None:
            loader.load_fact_resultats_politique(star_schema_data['fact_resultats_politique'], mode="append")
        else:
            logger.warning("‚ö†Ô∏è La table de faits est None, chargement ignor√©")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du chargement MySQL: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

    # D√©finition des chemins vers les fichiers consolid√©s
    election_csv = "data/processed_data/vote_presidentiel_par_dept_1965_2022_processed.csv"
    security_csv = "data/processed_data/delits_par_departement_1996_2022_processed.csv"
    socio_csv = "data/processed_data/pib_inflation_final_processed.csv"
    sante_csv = "data/processed_data/esperance_de_vie_par_departement_2000_2022_processed.csv"
    env_csv = "data/processed_data/parc-regional-annuel-prod-eolien-solaire_processed.csv"
    edu_csv = "data/processed_data/fr-en-etablissements-fermes_processed.csv"
    demo_csv = "data/processed_data/demographie_fusion_processed.csv"
    tech_csv = "data/processed_data/technologie_pib_france_1990_2023_processed.csv"

    # 3. G√©n√©ration du fichier consolid√© CSV
    logger.info("üîÑ G√©n√©ration du fichier consolid√©...")
    loader.generate_consolidated_csv_from_files(
        election_csv=election_csv,
        security_csv=security_csv,
        socio_csv=socio_csv,
        sante_csv=sante_csv,
        env_csv=env_csv,
        edu_csv=edu_csv,
        demo_csv=demo_csv,
        tech_csv=tech_csv,
        output_filename="consolidated_data.csv"
    )
    
    logger.info("‚úÖ Chargement des donn√©es termin√©")
    return


def main():
    """
    Point d'entr√©e principal de l'ETL utilisant des fonctions d√©compos√©es :
    - Extraction des donn√©es via extract_data()
    - Transformation des donn√©es via transform_data()
    - Chargement des donn√©es via load_data()
    """
    logger.info("üöÄ D√©marrage du processus ETL")

    try:
        # Extraction des donn√©es
        extracted_data, spark = extract_data()
        if extracted_data is None:
            logger.error("‚ùå √âchec de l'√©tape d'extraction. Arr√™t du programme.")
            return
            
        # Transformation des donn√©es (ajout du retour star_schema_data)
        transformed_data, star_schema_data = transform_data(extracted_data, spark)
        if transformed_data is None or star_schema_data is None:
            logger.error("‚ùå √âchec de l'√©tape de transformation. Arr√™t du programme.")
            return
            
        # Chargement des donn√©es (ajout du param√®tre star_schema_data)
        load_data(transformed_data, star_schema_data, spark, extracted_data['file_paths'])
        
        # Arr√™t de la session Spark
        from pyspark.sql import SparkSession
        spark_session = SparkSession.builder.getOrCreate()
        spark_session.stop()
        
        logger.info("‚úÖ Processus ETL termin√© avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du processus ETL : {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du processus ETL : {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise